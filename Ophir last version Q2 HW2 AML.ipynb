{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ophir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ophir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ophir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "import sklearn.neighbors\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction import text\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#lemmatization libraries \n",
    "import nltk.stem\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# punctuation + stop words libraries:\n",
    "from nltk.corpus import stopwords\n",
    "import re, string, timeit\n",
    "\n",
    "#stemming \n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(a) Parsing the txt files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1(a): Parsing Yelp, IMDB, and Amazon database:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = pd.read_csv(\"yelp_labelled.txt\", sep=\"\\t\", header=None, names=[\"sentence\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many values are there? How many positive and negative emotions (0/1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-0a2494051e90>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_imdb = pd.read_csv(\"imdb_labelled.txt\", sep=\" \\t\", header=None, names=[\"sentence\", \"label\"])\n"
     ]
    }
   ],
   "source": [
    "df_imdb = pd.read_csv(\"imdb_labelled.txt\", sep=\" \\t\", header=None, names=[\"sentence\", \"label\"])\n",
    "#Notice: IMDB required another space in order to parse the 1000 lines because it was badly formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many values are there? How many positive and negative emotions (0/1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing Amazon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon = pd.read_csv(\"amazon_cells_labelled.txt\", sep=\"\\t\", header=None, names=[\"sentence\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many values are there? How many positive and negative emotions (0/1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results - Amazon, IMDB and Yelp are balanced (50% negative 50% positive)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2(b): Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick your preprocessing strategy. Since these sentences are online reviews, they may contain significant amounts of noise and garbage. You may or may not want to do one or all of\n",
    "the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Lowercase all of the words.\n",
    "\n",
    "• Lemmatization of all the words (i.e., convert every word to its root so that all of “running,”\n",
    "“run,” and “runs” are converted to “run” and and all of “good,” “well,” “better,” and “best”\n",
    "are converted to “good”; this is easily done using nltk.stem).\n",
    "\n",
    "• Strip punctuation.\n",
    "\n",
    "• Strip the stop words, e.g., “the”, “and”, “or”.\n",
    "\n",
    "• Something else? Tell us about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercase all databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp[\"sentence\"] = df_yelp[\"sentence\"].str.lower()\n",
    "df_imdb[\"sentence\"] = df_imdb[\"sentence\"].str.lower()\n",
    "df_amazon[\"sentence\"] = df_amazon[\"sentence\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strip the stop words, e.g., “the”, “and”, “or”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "stop.remove(\"not\")\n",
    "stop.remove(\"nor\")\n",
    "# stop = text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp['sentence'] = df_yelp['sentence'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df_imdb['sentence'] = df_imdb['sentence'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df_amazon['sentence'] = df_amazon['sentence'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuation Strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that removes punctuation:\n",
    "def remove_punctuation(sentence):\n",
    "    sentence = re.sub(r'[^\\w\\s+]','',sentence)\n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp[\"sentence\"] = df_yelp['sentence'].apply(lambda x: remove_punctuation(x))\n",
    "df_imdb[\"sentence\"] = df_imdb['sentence'].apply(lambda x: remove_punctuation(x))\n",
    "df_amazon[\"sentence\"] = df_amazon['sentence'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = nltk.tokenize.WhitespaceTokenizer() \n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    list2 = word_tokenizer.tokenize(text)\n",
    "    lemmatized_sentence = ' '.join([lemmatizer.lemmatize(words) for words in list2])\n",
    "    return(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp['sentence'] = df_yelp['sentence'].apply(lambda x: lemmatize_text(x))\n",
    "df_imdb['sentence'] = df_imdb['sentence'].apply(lambda x: lemmatize_text(x))\n",
    "df_amazon['sentence'] = df_amazon['sentence'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2(C): Split training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each file use the first 400 instances for each label as the training set and the remaining 100 instances as testing set.\n",
    "\n",
    "In total, there are 2400 reviews for training and 600 reviews for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yelp - Divide to positive and negative data set and extract from there the train / test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into positive / negative datasets:\n",
    "df_yelp_pos = df_yelp[df_yelp['label'] == 1].reset_index(drop=True)   # positive emotion = 1\n",
    "df_yelp_neg = df_yelp[df_yelp['label'] == 0].reset_index(drop=True)   # Negative emotion = 0\n",
    "\n",
    "# For the positive dataset - divide into train / test datasets:\n",
    "df_yelp_train_pos = df_yelp_pos[:400]\n",
    "df_yelp_test_pos = df_yelp_pos[400:500]\n",
    "\n",
    "# For the negative dataset - divide into train / test datasets:\n",
    "df_yelp_train_neg = df_yelp_neg[:400]\n",
    "df_yelp_test_neg = df_yelp_neg[400:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB - Divide to positive and negative data set and extract from there the train / test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into positive / negative datasets:\n",
    "df_imdb_pos = df_imdb[df_imdb['label'] == 1].reset_index(drop=True)   # positive emotion = 1\n",
    "df_imdb_neg = df_imdb[df_imdb['label'] == 0].reset_index(drop=True)   # Negative emotion = 0\n",
    "\n",
    "# For positive - train / test datasets:\n",
    "df_imdb_train_pos = df_imdb_pos[:400]\n",
    "df_imdb_test_pos = df_imdb_pos[400:500]\n",
    "\n",
    "# For the negative dataset - divide into train / test datasets:\n",
    "df_imdb_train_neg = df_imdb_neg[:400]\n",
    "df_imdb_test_neg = df_imdb_neg[400:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amazon - Divide to positive and negative data set and extract from there the train / test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into positive / negative datasets:\n",
    "df_amazon_pos = df_amazon[df_amazon['label'] == 1].reset_index(drop=True)   # positive emotion = 1\n",
    "df_amazon_neg = df_amazon[df_amazon['label'] == 0].reset_index(drop=True)   # Negative emotion = 0\n",
    "\n",
    "# For positive - train / test datasets:\n",
    "df_amazon_train_pos = df_amazon_pos[:400]\n",
    "df_amazon_test_pos = df_amazon_pos[400:500]\n",
    "\n",
    "# For the negative dataset - divide into train / test datasets:\n",
    "df_amazon_train_neg = df_amazon_neg[:400]\n",
    "df_amazon_test_neg = df_amazon_neg[400:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat - train_df & test_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df_amazon_train_pos, df_amazon_train_neg, df_yelp_train_pos, df_yelp_train_neg,\n",
    "                                   df_imdb_train_pos, df_imdb_train_neg], ignore_index=True)\n",
    "\n",
    "#self check\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.concat([df_amazon_test_pos, df_amazon_test_neg, df_yelp_test_pos, df_yelp_test_neg,\n",
    "                                   df_yelp_test_pos, df_yelp_test_neg], ignore_index=True)\n",
    "\n",
    "#self check\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2(h)\n",
    "df_train_ngram = df_train.copy()\n",
    "df_test_ngram = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words model.\n",
    "\n",
    "Extract features and then represent each review using bag of words model, i.e., every word in the review becomes its own element in a feature vector. \n",
    "In order to do this, first, make one pass through all the reviews in the training set (Explain why we can’t\n",
    "use testing set at this point) and build a dictionary of unique words. \n",
    "Then, make another pass through the review in both the training set and testing set and count up the occurrences of\n",
    "each word in your dictionary. \n",
    "The i-th element of a review’s feature vector is the number of occurrences of the ith dictionary word in the review. \n",
    "Implement the bag of words model and report feature vectors of any two reviews in the training set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dictionary with all unique words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with all unique words and their count:\n",
    "word_freq = dict()\n",
    "for row in df_train['sentence']:\n",
    "    for word in row.split():\n",
    "        if word not in word_freq:\n",
    "            word_freq[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count values\n",
    "for row in df_train['sentence']:\n",
    "    for word in row.split():\n",
    "        word_freq[word] = word_freq[word] + 1\n",
    "for row in df_test['sentence']:\n",
    "    for word in row.split():\n",
    "        if word in word_freq:\n",
    "            word_freq[word] = word_freq[word] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not': 304, 'mention': 6, 'combination': 3, 'pear': 1, 'almond': 1, 'bacon': 6, 'big': 19, 'winner': 2, 'patio': 3, 'seating': 5, 'comfortable': 20, 'friend': 11, 'pasta': 6, 'also': 77, 'bad': 89, 'barely': 13, 'touched': 1, 'it': 118, 'say': 44, 'food': 147, 'amazing': 31, 'arrives': 1, 'meh': 2, 'sorry': 2, 'made': 56, 'purchase': 15, 'main': 4, 'player': 8, 'mesmerising': 1, 'damian': 1, 'talented': 3, 'versatile': 1, 'many': 29, 'way': 44, 'writing': 12, 'portraying': 2, 'different': 13, 'character': 42, 'screen': 19, 'wanted': 11, 'price': 47, 'think': 47, 'place': 149, 'would': 90, 'much': 51, 'rather': 12, 'gone': 5, 'several': 12, 'time': 128, 'past': 3, 'experience': 38, 'always': 28, 'great': 217, 'ursula': 1, 'burton': 1, 'portrayal': 4, 'nun': 2, 'touching': 2, 'funny': 17, 'making': 5, 'fun': 8, 'church': 2, 'fresh': 20, 'subtle': 4, 'sublime': 2, 'effect': 9, 'taste': 14, 'mom': 3, 'multigrain': 1, 'pumpkin': 1, 'pancake': 3, 'pecan': 1, 'butter': 4, 'fluffy': 1, 'delicious': 24, 'ring': 3, 'toneoverall': 1, 'good': 234, 'phone': 173, 'buy': 20, 'better': 55, 'new': 30, 'wish': 5, 'could': 52, 'return': 13, 'unit': 9, 'get': 76, 'back': 83, 'money': 31, 'interesting': 12, 'part': 22, 'town': 8, 'cant': 28, 'store': 6, 'anything': 13, 'number': 6, 'sim': 1, 'even': 75, 'tell': 12, 'talent': 3, 'pathetic': 5, 'line': 18, 'speak': 3, 'director': 11, 'gave': 10, 'action': 5, 'got': 37, 'small': 17, 'adorable': 4, 'wonderful': 19, 'location': 8, 'lie': 2, 'story': 18, 'contrast': 2, 'downside': 1, 'service': 126, 'mean': 8, 'really': 102, 'famous': 2, 'fish': 6, 'chip': 11, 'terrible': 32, 'side': 18, 'delish': 3, 'mixed': 1, 'mushroom': 3, 'yukon': 1, 'gold': 2, 'puree': 3, 'white': 12, 'corn': 2, 'beateous': 1, 'try': 17, 'going': 36, 'empty': 5, 'damn': 4, 'steak': 19, 'feel': 27, 'headset': 55, 'wear': 9, 'glass': 4, 'sometimes': 6, 'unfortunately': 12, 'easy': 17, 'accidentally': 2, 'activate': 1, 'gentletouch': 1, 'button': 10, 'touch': 6, 'face': 10, 'listening': 2, 'hate': 8, 'earbugs': 1, 'avoid': 13, 'chef': 5, 'generous': 3, 'came': 36, 'around': 18, 'twice': 12, 'take': 23, 'picture': 18, 'him': 6, 'performed': 2, 'fantastic': 20, 'here': 30, 'kid': 10, 'play': 12, 'area': 12, 'nasty': 5, 'never': 46, 'hard': 16, 'rock': 5, 'casino': 1, 'before': 6, 'ever': 69, 'step': 3, 'forward': 1, 'again': 32, 'case': 39, 'ive': 61, 'tried': 18, 'normally': 2, 'fall': 6, 'apart': 3, 'month': 12, 'one': 130, 'seems': 9, 'long': 23, 'haul': 1, 'happy': 26, 'disappointing': 14, 'aspect': 4, 'lack': 8, 'notable': 2, 'gore': 1, 'beware': 3, 'sucked': 12, 'expected': 8, 'imagined': 1, 'movie': 165, 'pied': 1, 'off': 10, 'buyerbe': 1, 'careful': 2, 'work': 104, 'like': 120, 'charm': 7, 'advertised': 2, 'impressed': 22, 'product': 57, 'standout': 1, 'scene': 26, 'best': 79, 'show': 22, 'strong': 8, 'sibling': 1, 'bond': 1, 'other': 3, 'forced': 3, 'everything': 34, 'bluetoooth': 1, 'still': 34, 'fit': 25, 'ear': 41, 'incredible': 11, 'chain': 1, 'im': 58, 'fan': 9, 'of': 4, 'beat': 7, 'easily': 9, 'sanyo': 1, 'survived': 1, 'dozen': 3, 'drop': 6, 'blacktop': 1, 'without': 14, 'ill': 15, '5': 17, 'star': 28, 'sound': 50, 'quality': 65, 'value': 11, 'loved': 19, 'dissapointing': 1, 'performance': 20, 'directing': 7, 'pretentious': 4, 'self': 3, 'proclaimed': 1, 'coffee': 2, 'cafe': 3, 'wildly': 1, 'disappointed': 37, 'excellently': 2, 'produced': 3, 'scifis': 1, 'producer': 2, 'scot': 1, 'vandiver': 1, 'know': 31, 'seemed': 7, 'sketchy': 1, 'technology': 2, 'wellwell': 1, 'waste': 28, 'fast': 10, 'shipping': 5, 'using': 13, 'iriver': 1, 'spinn': 1, 'with': 5, 'fine': 21, 'surprised': 3, 'car': 22, 'charger': 22, 'there': 22, 'review': 15, 'sadly': 1, 'gordon': 1, 'ramseys': 1, 'shall': 1, 'sharply': 2, 'next': 19, 'trip': 7, 'vega': 23, 'horrible': 20, 'serve': 3, 'vinaigrette': 1, 'may': 13, 'make': 59, 'overall': 19, 'dish': 17, 'john': 7, 'bailey': 1, 'crisp': 4, 'beautifully': 3, 'colored': 2, 'cinematography': 8, 'production': 3, 'design': 13, 'costume': 2, 'eiko': 1, 'ishioka': 1, 'went': 22, 'memorable': 5, 'coppola': 2, 'dracula': 1, 'received': 13, 'well': 87, 'deserved': 2, 'oscar': 2, 'business': 8, 'dinner': 11, 'dollar': 3, 'elsewhere': 8, 'music': 16, 'film': 138, 'nice': 60, 'too': 17, 'love': 69, 'thin': 9, 'is': 14, 'friendly': 33, 'job': 18, 'utterly': 4, 'merit': 1, 'level': 7, 'akin': 1, 'torture': 4, 'pure': 3, 'brilliance': 1, 'choice': 7, 'classywarm': 1, 'atmosphere': 12, 'appetizer': 3, 'succulent': 1, 'baseball': 1, 'suck': 10, 'achievement': 1, 'sobaditsgood': 1, 'sobaditsmemorable': 1, 'seen': 16, 'half': 10, 'boring': 7, 'selfindulgent': 2, 'piece': 27, 'junk': 9, 'waiter': 8, 'helpful': 10, 'rarely': 2, 'checked': 4, 'u': 28, 'lordy': 1, 'khao': 1, 'soi': 1, 'missed': 4, 'curry': 2, 'lover': 3, 'bother': 6, 'contacting': 1, 'company': 10, 'learned': 1, 'lesson': 1, 'bought': 21, 'form': 4, 'online': 1, 'anyway': 3, 'summary': 3, 'largely': 2, 'dining': 8, 'brilliant': 7, 'believe': 13, 'dirty': 6, 'oyster': 1, 'were': 5, '10': 23, 'minute': 37, 'waiting': 8, 'salad': 22, 'realized': 2, 'coming': 16, 'soon': 13, 'ordered': 19, 'took': 14, '40': 4, 'pizza': 21, 'another': 21, 'acting': 29, 'decidely': 1, 'wooden': 2, 'though': 18, 'worse': 13, 'period': 6, 'universal': 1, 'b': 1, 'nicest': 3, 'restaurant': 36, 'owner': 8, 'come': 22, 'across': 1, 'monica': 1, 'bellucci': 1, 'look': 38, 'beautiful': 16, 'cover': 8, 'girl': 8, 'example': 3, 'hollywood': 1, 'used': 27, 'exploit': 1, 'woman': 3, 'financial': 1, 'gain': 1, 'reception': 15, 'generally': 4, 'basically': 4, 'disappointment': 14, 'go': 75, 'customize': 1, 'order': 22, 'usual': 4, 'eggplant': 2, 'green': 5, 'bean': 6, 'stir': 2, 'fry': 16, 'solid': 6, 'keyboard': 4, 'awsome': 1, 'device': 14, 'kris': 1, 'kristoffersen': 1, 'difference': 2, 'switch': 2, '3': 11, 'unreliable': 4, 'giving': 3, 'up': 15, 'however': 18, 'decent': 10, 'balance': 3, 'thing': 51, 'dropped': 9, 'ball': 3, 'out': 14, 'warranty': 2, 'problem': 30, 'reoccurebottom': 1, 'put': 12, 'somewhere': 1, 'else': 8, 'cingular': 3, 'support': 4, 'worthless': 3, 'mussel': 1, 'cooked': 7, 'wine': 7, 'reduction': 1, 'duck': 4, 'tender': 8, 'potato': 10, 'superb': 6, 'network': 4, 'loop': 2, 'needed': 7, 'tiny': 3, 'familiar': 2, 'check': 10, 'lane': 2, 'lousy': 3, 'fact': 11, 'tremendously': 2, 'build': 1, 'unlike': 1, 'cheap': 16, 's': 2, 'eating': 7, 'littered': 1, 'overt': 1, 'racial': 3, 'slur': 1, 'towards': 4, 'black': 16, 'cast': 16, 'member': 3, 'depicted': 1, 'moron': 1, 'boob': 1, 'essentially': 2, 'communication': 2, 'tool': 5, 'communicate': 1, 'voice': 9, 'recognition': 2, 'thru': 2, 'handset': 1, 'excellent': 51, 'clean': 11, 'inexpensive': 3, 'boot': 3, 'drive': 6, 'north': 1, 'scottsdale': 1, 'bit': 19, 'portion': 7, 'huge': 11, 'anne': 3, 'heche': 1, 'convincing': 3, 'people': 32, 'found': 23, 'roth': 1, 'pearl': 1, 'considering': 6, 'relation': 1, 'taylor': 2, 'stanwyck': 2, 'surprising': 1, 'little': 35, 'chemistry': 2, 'two': 27, 'them': 12, 'enjoyment': 1, 'see': 39, 'run': 5, 'game': 12, 'dangerous': 2, 'awful': 21, 'dialogue': 9, 'hopeless': 1, 'overacting': 2, 'everyone': 13, 'shot': 10, 'top': 10, 'real': 28, 'space': 3, 'particular': 4, 'model': 2, 'motorola': 11, 'q': 3, 'smartphone': 1, 'cut': 7, 'day': 27, 'flavored': 1, 'year': 32, 'ago': 8, 'posted': 1, 'detailed': 1, 'comment': 3, 'grey': 1, 'fire': 3, 'red': 4, 'color': 9, 'frightening': 2, 'least': 13, 'comprehensible': 1, 'elegantly': 1, 'decorated': 2, 'secondly': 1, 'hitchcock': 6, 'pretty': 44, 'perfected': 1, 'thriller': 5, 'chase': 1, 'lucy': 1, 'bell': 2, 'higher': 1, 'crap': 10, 'sink': 1, 'low': 14, 'quite': 25, 'depressing': 2, 'probably': 20, 'important': 8, 'babie': 1, 'bop': 1, 'cute': 5, 'buyer': 2, 'remorse': 1, 'embarrassing': 4, 'away': 13, 'pulled': 4, 'pork': 5, 'soooo': 3, 'helen': 1, 'baxendale': 1, 'credible': 1, 'lady': 7, 'macbeth': 2, 'cheerfull': 1, 'naughty': 1, 'deadly': 1, 'blood': 2, 'evil': 1, 'alexander': 2, 'nevsky': 1, 'schrader': 2, 'resume': 1, 'full': 13, 'amateurish': 1, 'greek': 3, 'dressing': 3, 'creamy': 2, 'flavorful': 4, 'tied': 1, 'conversation': 5, 'lasting': 3, '45': 2, 'minutesmajor': 1, 'waitress': 11, 'slow': 16, '1010': 3, 'enjoy': 11, 'politically': 1, 'correct': 3, 'authentic': 8, 'leather': 5, 'shine': 1, 'comfort': 3, 'i': 6, 'recommend': 45, 'staff': 21, 'mainly': 1, 'broke': 9, 'purchasing': 2, 'special': 13, 'score': 3, 'integral': 1, 'element': 2, 'helping': 1, 'enjoyable': 4, 'cartoon': 5, 'camera': 19, 'nutshell': 1, '1': 13, 'restaraunt': 1, 'smell': 3, 'market': 4, 'sewer': 1, 'eargels': 2, 'channel': 2, 'directly': 1, 'seem': 5, 'increase': 1, 'volume': 12, 'clarity': 5, 'everyday': 1, 'hold': 11, 'ambience': 4, 'playing': 8, '20th': 1, 'century': 2, 'fox': 2, 'road': 1, 'house': 10, '1948': 1, 'silly': 1, 'noir': 1, 'implausible': 2, 'unmitigated': 1, 'bore': 2, 'tom': 4, 'hank': 1, 'actor': 23, 'bt': 3, 'disapoinment': 1, 'camp': 1, 'penne': 1, 'vodka': 1, 'transmit': 1, 'audio': 8, 'spoiler': 5, 'want': 29, 'worth': 26, 'possible': 7, 'redeemed': 1, 'mst3k': 1, 'fodder': 1, 'convoluted': 1, 'plot': 20, 'convince': 1, 'me': 21, 'watched': 10, 'weird': 4, 'questioning': 1, 'glance': 3, 'angela': 1, 'bennett': 1, 'computer': 5, 'expert': 1, 'home': 10, 'whiny': 1, 'pointless': 1, 'perfect': 21, 'redeeming': 3, 'remake': 3, 'killer': 4, 'course': 8, 'breaking': 2, 'finally': 7, 'sign': 4, 'improvement': 2, 'happen': 2, 'over': 1, 'might': 7, 'far': 25, 'asleep': 1, 'bar': 18, 'recall': 1, 'charged': 4, 'tap': 3, 'water': 5, 'seriously': 14, 'breakfast': 11, 'enough': 36, 'mess': 9, 'marred': 1, 'constant': 1, 'use': 49, 'studio': 1, 'set': 12, 'indoor': 3, 'exterior': 2, 'definitely': 31, 'checking': 3, 'literally': 8, 'wonder': 3, 'excerpt': 1, 'jiggle': 1, 'plug': 13, 'right': 32, 'fully': 2, 'bed': 1, 'turned': 5, 'blue': 5, 'tooth': 2, 'wifi': 1, 'noticed': 2, '20': 6, 'left': 12, 'morning': 1, 'created': 4, 'unique': 3, 'feeling': 12, 'watch': 16, 'consolation': 1, 'actress': 4, 'sister': 4, 'role': 7, 'cool': 20, 'done': 14, 'second': 11, 'motorolas': 2, 'website': 5, 'followed': 1, 'direction': 5, 'pair': 3, 'sweet': 7, 'moment': 5, 'driving': 3, 'tucson': 1, 'true': 4, 'classic': 8, 'quick': 9, 'served': 7, 'folk': 4, 'infatuated': 1, 'thought': 20, 'errol': 2, 'flynn': 2, 'custer': 1, 'since': 20, 'become': 5, 'favourite': 3, '35': 4, 'bay': 5, 'plater': 1, 'chilly': 2, 'unremarkable': 1, 'author': 1, 'livingworking': 1, 'abstruse': 1, 'culture': 1, 'hand': 13, 'free': 7, 'noca': 1, 'summer': 3, 'dine': 2, 'charming': 2, 'outdoor': 1, 'delightful': 4, 'conclusion': 3, 'volcano': 2, 'los': 3, 'angeles': 3, 'nothing': 24, 'nonsense': 2, 'terrific': 6, 'scenery': 2, 'saw': 9, 'mirrormask': 1, 'last': 22, 'night': 20, 'unsatisfactory': 2, 'disgusted': 1, 'sure': 17, 'human': 9, 'hair': 4, 'casting': 6, 'jimmy': 2, 'buffet': 18, 'science': 1, 'teacher': 1, 'totally': 17, 'fascinated': 1, 'dancing': 3, 'prosgood': 1, 'style': 11, 'more': 9, 'mistake': 7, 'wa': 9, 'headphone': 6, 'bluetooth': 17, 'week': 13, 'nano': 1, 'stated': 2, 'itmy': 1, 'son': 4, 'dissapointed': 1, 'igo': 2, 'tip': 6, 'range': 6, 'able': 4, 'roam': 1, 'living': 5, 'room': 7, 'receptionsound': 1, 'issue': 4, 'and': 7, 'honestly': 4, 'often': 5, 'samsung': 5, 'flipphones': 1, 'feature': 11, 'started': 12, 'dislike': 1, 'getting': 14, 'anytime': 6, 'theater': 4, 'lilt': 1, 'joy': 7, 'heart': 9, 'hope': 9, 'race': 2, 'bagel': 2, 'grocery': 1, 'burger': 17, 'doughy': 1, 'flavorless': 2, 'wrong': 8, 'donut': 1, 'need': 16, 'ask': 9, 'signal': 7, 'filmiing': 1, 'le': 11, 'expansive': 1, 'furthermore': 1, 'find': 19, 'hour': 23, 'operation': 1, 'tasty': 13, 'texture': 4, 'couple': 10, 'drink': 10, 'sporting': 1, 'event': 4, 'wall': 8, 'covered': 2, 'tv': 7, 'virgin': 1, 'wireless': 3, 'hit': 8, 'spot': 12, 'something': 11, 'healthy': 4, 'lacking': 7, 'quantity': 1, 'flavor': 17, 'all': 24, 'satisfied': 5, 'confirm': 1, 'unfunny': 2, 'generic': 2, 'managed': 3, 'give': 28, 'entire': 6, 'exaggerating': 1, 'every': 36, 'point': 7, 'joke': 8, 'told': 8, 'trailer': 1, 'third': 4, 'cheese': 3, 'cold': 13, 'excited': 2, 'oh': 7, 'yeah': 3, 'storyline': 4, 'carry': 4, 'highest': 2, 'antiglare': 1, 'protector': 2, 'date': 4, 'eloquently': 1, 'francis': 1, 'ford': 1, '25': 2, 'earlier': 4, 'unfolds': 2, 'gradually': 1, 'leaf': 4, 'develop': 1, 'forgot': 2, 'wow': 6, 'asked': 6, 'bill': 5, 'leave': 6, 'bring': 9, 'either': 12, 'first': 45, 'timer': 1, 'trash': 3, 'watching': 17, 'washing': 1, 'machine': 3, 'twirling': 1, 'hurt': 2, 'eye': 6, 'sushi': 15, 'kabuki': 1, 'overpriced': 10, 'overhip': 1, 'underservices': 1, 'servicecheck': 1, 'sturdy': 5, 'nokia': 7, 'are': 2, 'shifting': 1, 'bubbling': 1, 'peeling': 1, 'scratch': 1, 'nothingi': 1, 'happier': 4, 'droid': 1, 'kind': 16, 'wasted': 11, 'properly': 4, 'emily': 2, 'watson': 2, 'understand': 11, 'loudspeaker': 1, 'option': 8, 'bumper': 1, 'light': 12, 'appealing': 4, 'description': 4, 'said': 18, 'craving': 1, 'pushed': 1, 'function': 3, 'jawbone': 3, 'replace': 4, 'memory': 5, 'murky': 1, 'enjoyed': 14, 'single': 6, 'episode': 4, 'related': 1, 'please': 5, 'dont': 8, 'no': 3, 'eat': 26, 'stranger': 2, 'plus': 7, '8': 6, 'buck': 3, 'guy': 6, 'loving': 1, 'worst': 35, 'he': 4, 'eaten': 5, 'uncomfortable': 3, 'lg': 4, 'vx9900': 1, 'env': 1, 'greedy': 1, 'corporation': 1, 'dime': 1, 'yet': 10, 'battery': 47, 'thats': 15, 'three': 11, 'charging': 5, 'educational': 1, 'child': 7, 'old': 16, 'simply': 14, 'rumble': 1, 'desperately': 1, 'depending': 1, 'addition': 4, 'stuff': 5, 'arguing': 1, 'verizon': 8, 'regarding': 2, 'call': 27, 'returned': 3, 'average': 10, 'razr': 5, 'owneryou': 1, 'must': 18, 'this': 18, 'glad': 8, 'purchased': 4, 'lived': 2, '1979': 1, 'stepped': 1, 'foot': 4, 'amazon': 9, 'high': 10, 'priced': 7, 'loud': 6, 'buzzing': 2, 'override': 2, 'you': 13, 'spends': 1, 'talking': 2, 'six': 2, 'inch': 2, 'wire': 2, 'salsa': 5, 'boy': 4, 'sucker': 1, 'dry': 7, 'unrealistic': 1, 'throughout': 5, 'whole': 11, '90': 6, 'utter': 2, 'looked': 5, '70000': 1, 'evening': 2, 'companion': 1, 'meeverything': 1, 'villain': 1, 'rent': 4, 'michael': 1, 'ironside': 1, 'mouth': 6, 'belly': 3, 'pleased': 9, 'song': 10, 'explain': 3, 'emotion': 4, 'subject': 2, 'jay': 1, 'adam': 1, 'unfortunate': 1, 'life': 22, 'talk': 22, 'man': 12, 'neil': 1, 'young': 4, 'played': 9, 'evokes': 1, 'stupid': 15, 'keep': 10, 'buying': 5, 'cradle': 2, 'kit': 1, 'relationship': 4, 'bakery': 3, 'assistant': 2, 'cumbersome': 2, 'selection': 15, 'opportunity': 2, 'today': 9, 'sample': 2, 'handle': 2, 'tough': 2, 'dignity': 1, 'grace': 3, 'shocking': 1, 'outlandish': 1, 'array': 3, 'psychotic': 1, 'lovable': 1, 'nut': 4, 'pyromaniac': 1, 'waylaid': 1, 'bored': 1, 'care': 10, 'happened': 6, 'switched': 1, 'thoroughly': 3, 'clear': 13, 'provides': 3, 'protection': 3, 'classy': 1, 'perhaps': 7, 'caught': 2, 'judging': 2, 'inspired': 1, 'fourth': 1, 'jabra': 8, 'which': 3, 'hated': 3, 'placed': 4, 'treo': 4, 'snug': 1, 'lot': 32, 'extra': 6, 'item': 21, 'recieve': 1, 'absolutely': 22, 'apartment': 1, 'hoped': 1, 'poler': 1, 'bear': 1, 'kinda': 2, 'cutebut': 1, 'anyone': 21, 'question': 1, 'fort': 1, 'steele': 1, 'contained': 3, 'allstar': 1, 'opened': 3, '2': 31, 'thumb': 6, 'hockey': 1, 'defensemen': 1, 'theyre': 6, 'goalie': 1, 'diving': 1, 'wide': 3, 'net': 1, 'etc': 5, 'server': 23, 'forth': 2, 'helped': 3, 'now': 7, 'older': 2, 'wayne': 2, 'later': 7, 'lost': 10, 'power': 4, 'amusing': 1, 'convenient': 3, 'simple': 10, 'ride': 1, 'smoother': 1, 'trashy': 1, 'cult': 4, 'continuity': 2, 'error': 1, 'user': 3, 'commented': 1, 'garage': 1, 'joes': 2, 'glassesthe': 1, 'facial': 1, 'configuration': 1, 'change': 3, 'trying': 8, 'crust': 2, 'teeth': 2, 'sore': 1, 'cost': 7, 'stream': 1, 'submerged': 1, '15': 3, 'gotta': 1, 'closeup': 2, 'slimy': 1, 'drooling': 1, 'table': 17, 'wait': 17, 'state': 1, 'allow': 2, 'cell': 14, 'usage': 1, 'staying': 3, 'mgm': 1, 'cannot': 10, 'agreed': 1, 'rate': 3, '110': 2, 'scale': 3, 'especially': 15, 'designed': 1, 'amazingstylized': 1, 'effective': 3, 'others': 8, 'consumer': 2, 'expertconnisseur': 1, 'topic': 1, 'running': 6, 'husband': 5, 'sunglass': 3, 'crepe': 1, 'station': 4, 'expecting': 1, 'material': 3, 'sitting': 3, 'fairly': 4, 'but': 3, 'ended': 5, '30': 7, 'arrived': 8, 'outshining': 1, 'halibut': 1, 'suffers': 1, 'dessert': 10, '4': 6, 'building': 4, 'maybe': 7, 'poor': 27, 'hummh': 1, 'slowmotion': 1, 'needlessly': 1, 'repeat': 1, 'backed': 1, 'word': 10, 'thrown': 2, 'reason': 8, 'whatsoever': 6, 'vehicle': 2, 'flake': 1, 'box': 4, 'directorial': 1, 'bordered': 1, 'stupidity': 1, 'excessively': 1, 'phony': 1, 'contrived': 1, 'painful': 3, 'sit': 1, 'through': 1, 'compromise': 2, 'qwerty': 1, 'basic': 2, 'keypad': 3, 'beer': 12, 'paying': 1, '785': 1, 'hot': 14, 'dog': 5, 'meal': 17, 'wienerschnitzel': 1, 'idea': 6, 'plastic': 7, 'break': 9, 'clip': 5, 'sole': 1, 'bright': 1, 'jonah': 2, 'hill': 3, 'who': 3, 'almost': 14, 'unrecognizable': 2, 'recent': 3, 'superbad': 1, 'due': 4, 'amount': 10, 'weight': 2, 'interim': 1, 'completely': 14, 'dead': 4, 'nargile': 1, 'elia': 1, 'koteasjack': 1, 'palance': 1, 'angelina': 1, 'nakedbilly': 1, 'drago': 4, 'appears': 3, '+': 1, 'cameo': 1, 'sven': 1, 'ole': 1, 'thorsen': 1, 'help': 5, 'budget': 4, 'mother': 3, 'central': 2, 'theme': 3, 'handled': 3, 'ineptly': 1, 'stereotypically': 1, 'depth': 4, 'imagination': 6, 'jamie': 2, 'foxx': 1, 'ray': 4, 'charles': 4, 'walked': 5, 'smelled': 1, 'grease': 2, 'trap': 2, 'bt50': 1, 'short': 8, 'certainly': 10, 'pull': 5, 'punch': 1, 'ending': 9, 'sprint': 3, 'charge': 16, 'tolerate': 1, 'political': 1, 'incorrectness': 1, 'artistic': 1, 'freedom': 3, 'suspension': 1, 'disbelief': 2, 'slavic': 1, 'female': 3, 'lame': 4, 'minor': 1, 'mediocre': 12, 'pg13': 2, 'complete': 3, 'nonsequel': 1, 'changing': 3, 'tone': 3, 'pgrated': 1, 'family': 21, 'finger': 2, 'menu': 23, 'kindle': 1, 'powerful': 1, 'exploration': 1, 'nature': 2, 'art': 8, 'mind': 6, 'gonna': 2, 'complaint': 5, 'standard': 2, '5of': 1, 'entertaining': 3, 'nonetheless': 1, 'holster': 3, 'match': 3, 'photo': 1, 'ad': 1, 'homemade': 4, 'plenty': 3, 'humorous': 2, 'reccommend': 1, 'slide': 1, 'grip': 1, 'prevents': 1, 'slipping': 1, 'add': 2, 'betty': 1, 'jean': 2, 'smart': 3, 'working': 12, 'handy': 2, 'relaxing': 1, 'late': 3, 'viewing': 2, 'to': 8, 'linksys': 1, 'exchange': 2, 'refurb': 1, 'believable': 3, 'idiot': 1, 'produce': 2, 'season': 1, 'rice': 5, 'reasonably': 5, 'bamboo': 1, 'shoot': 1, 'bread': 7, 'topvery': 1, 'original': 9, 'longwearing': 1, 'condition': 1, 'tremendous': 3, 'leftover': 1, 'stale': 3, 'lovely': 5, 'duo': 1, 'violinist': 1, 'requested': 1, 'awesome': 26, 'ebay': 1, 'learn': 3, 'artist': 2, 'surefire': 1, 'gx2': 1, 'perfectly': 12, 'advise': 4, 'fooled': 1, 'chosen': 1, 'tortured': 1, 'disgusting': 5, 'blatant': 1, 'american': 3, 'propaganda': 1, 'hackneyed': 2, 'billy': 2, 'bob': 1, 'rise': 1, 'script': 18, 'grossed': 2, 'intelligent': 2, 'masterful': 2, 'intelligence': 3, 'obviously': 9, 'sense': 4, 'pitiful': 2, 'attempt': 4, 'chicken': 22, 'wing': 4, 'driest': 2, 'meat': 12, 'wind': 4, 'useless': 7, 'vanilla': 1, 'ice': 7, 'cream': 5, 'smooth': 1, 'profiterole': 1, 'chou': 1, 'pastry': 1, 'absolute': 1, 'visit': 5, 'whatever': 6, 'or': 2, 'surface': 1, 'superbly': 2, 'crafted': 2, 'underneath': 2, 'hear': 14, 'garbage': 5, 'replacement': 3, 'died': 2, 'lately': 1, 'extremely': 12, 'portable': 1, 'anythinga': 1, 'rocked': 1, 'world': 9, 'social': 1, 'physical': 1, 'outlet': 4, 'internet': 6, 'excrutiatingly': 1, 'final': 3, 'behing': 1, '5020': 1, 'comfortible': 1, '24': 1, 'pain': 1, 'flawed': 3, 'dirt': 2, 'burned': 1, 'saganaki': 1, 'compared': 1, 'previous': 2, 'wired': 2, 'that': 17, 'plugged': 3, 'manager': 6, 'exactly': 5, 'latched': 1, 'endearing': 1, 'host': 1, 'bitch': 1, 'fried': 5, 'peachykeen': 1, 'shattered': 1, 'recover': 1, 'practically': 2, 'â': 4, 'masterpiece': 3, 'sea': 1, 'faux': 3, 'supposedly': 2, '375': 1, 'apparently': 2, 'samsungcrap': 1, 'crappy': 1, 'e715': 1, 'seeen': 1, 'preparing': 2, 'insulted': 4, 'inviting': 1, 'near': 1, 'inside': 13, 'very': 8, 'serious': 2, 'worthwhile': 2, 'usefulness': 1, 'expect': 15, 'filmmaker': 2, 'nor': 1, 'hide': 1, 'head': 5, 'sand': 1, 'id': 15, 'spent': 3, 'technically': 1, 'impressive': 5, 'camerawork': 4, 'riz': 1, 'ortolani': 1, 'particularly': 4, 'recurring': 1, 'unaccompanied': 1, 'vocal': 1, 'distant': 1, 'delight': 5, 'chinese': 6, 'forgery': 1, 'abound': 1, 'pleasant': 4, 'deal': 13, 'honor': 1, 'hut': 1, 'coupon': 2, 'sony': 3, 'ericsson': 1, 'w810i': 2, 'worked': 21, 'bbq': 1, 'lighter': 1, 'fare': 4, 'reasonable': 8, 'pricing': 4, 'public': 2, 'notch': 1, 'pale': 1, 'instead': 5, 'char': 2, 'concrete': 1, 'knock': 1, 'wood': 1, 'sturdiness': 1, 'paul': 3, 'indeed': 3, 'about': 2, 'mishima': 2, 'complex': 2, 'load': 3, 'super': 13, 'expensive': 4, 'suspense': 4, 'frustration': 2, 'retarded': 1, 'creak': 1, 'floor': 1, 'effort': 4, 'message': 3, 'serivce': 1, 'forget': 4, 'microsofts': 1, 'tech': 2, 'pita': 4, 'hummus': 4, 'refreshing': 1, 'flush': 1, 'toilet': 1, 'ugly': 2, 'originally': 1, 'discarded': 1, 'scratched': 3, 'seeing': 6, 'mickey': 4, 'turkey': 2, 'straw': 1, 'highly': 21, 'imaginative': 2, 'if': 1, 'occasionally': 4, 'cruel': 1, 'drawback': 1, 'mp3': 1, 'front': 7, 'let': 11, 'pause': 1, 'skip': 2, 'lock': 3, 'thanks': 4, 'released': 2, 'remaining': 1, 'survivor': 1, 'ferry': 1, 'disaster': 3, 'valentine': 1, 'judge': 4, 'together': 9, 'solidifying': 1, 'happiness': 1, 'suffering': 2, 'dealt': 1, 'passed': 4, 'mark': 2, '100': 3, 'functional': 1, 'uneasy': 1, 'scared': 2, 'longer': 6, 'on': 8, 'sauce': 13, 'slaw': 1, 'drenched': 1, 'mayo': 1, 'whenever': 2, 'tvnever': 1, 'already': 3, 'memorized': 1, 'trond': 1, 'fausa': 1, 'aurvãg': 1, 'bothersome': 1, 'why': 3, 'pandering': 1, 'audience': 4, 'sabotage': 1, 'reading': 4, 'card': 2, 'turn': 12, 'mexican': 4, 'bunch': 3, 'choose': 3, 'from': 3, 'unusable': 2, 'moving': 3, 'freeway': 1, 'speed': 1, 'wilkinson': 3, 'end': 16, 'el': 1, 'fumbling': 1, 'hanky': 1, 'among': 2, 'male': 1, 'alike': 1, 'kiddos': 1, 'jason': 1, 'connery': 1, 'moved': 1, 'tear': 2, 'monolog': 1, 'brief': 2, 'candle': 1, 'outhe': 1, 'sphere': 1, 'moral': 2, 'decay': 2, 'dark': 4, 'force': 1, 'extraordinary': 2, 'mortified': 1, 'owns': 1, 'spacek': 1, 'owned': 6, 'coal': 1, 'miner': 1, 'daughter': 3, 'quaid': 1, 'angry': 2, 'hundred': 1, 'contact': 4, 'imagine': 2, 'sending': 4, 'realistic': 2, 'gotten': 5, 'ballet': 1, 'repertory': 1, 'dressed': 1, 'treated': 3, 'rudely': 1, 'guess': 9, 'liked': 13, 'detail': 1, 'dysfunctionhe': 1, 'recently': 6, 'stay': 12, 'connected': 2, 'disconnected': 1, 'honeslty': 1, 'felt': 16, 'tinny': 3, 'fella': 1, 'huevos': 1, 'rancheros': 1, 'google': 1, 'smashburger': 1, 'pop': 2, 'roast': 2, 'beef': 5, 'bland': 15, 'steamboat': 1, 'willie': 1, 'amazingly': 1, 'cinema': 8, 'history': 6, 'management': 6, 'instruction': 5, 'microphone': 3, 'jack': 1, 'recommended': 8, 'tasted': 8, 'supposed': 3, 'popcorn': 1, 'comedy': 2, 'insult': 4, 'incredibly': 4, 'border': 1, 'offensive': 2, 'wise': 1, 'decision': 4, 'unless': 6, 'starving': 1, 'foodservice': 1, 'while': 5, 'operates': 1, 'weak': 7, 'provided': 5, 'smile': 2, 'wrap': 3, 'trilogy': 3, 'prepared': 2, 'ordeal': 1, 'begin': 3, 'matter': 2, 'progress': 1, 'anguish': 1, 'honest': 5, 'unbelievable': 5, 'foolish': 1, 'tolerance': 1, 'rude': 10, 'customer': 18, 'polite': 1, 'wash': 1, 'otherwise': 2, 'bowl': 2, 'pho': 6, 'lion': 3, 'written': 5, 'acted': 2, 'empowerment': 1, 'jx10': 1, 'series': 6, 'flawlessly': 2, 'moto': 2, 'figure': 2, 'the': 4, 'quit': 2, 'soooooo': 1, 'freaking': 1, 'sandwich': 12, 'paper': 6, 'soyo': 1, 'obvious': 2, 'lesser': 1, 'have': 5, 'typical': 2, 'describe': 3, 'connection': 6, 'decided': 2, 'send': 3, 'verge': 1, 'attack': 2, 'rating': 8, '010': 2, 'grade': 1, 'z': 1, 'note': 6, 'f': 1, 'breakfastlunch': 1, 'omg': 2, 'delicioso': 1, 'breakage': 1, 'unacceptible': 1, 'perfection': 2, 'impeccable': 2, 'burrittos': 1, 'blah': 2, 'lifeoh': 1, 'gosh': 2, 'holding': 2, 'eew': 1, 'overhaul': 1, 'charcoal': 2, 'grill': 2, 'fell': 3, 'flat': 4, 'venture': 1, 'along': 4, 'airline': 1, 'texas': 1, 'article': 1, 'read': 2, 'focused': 2, 'spice': 3, 'can': 1, 'instant': 1, 'soundtrack': 4, 'catchy': 1, 'credit': 4, 'gross': 3, 'salmon': 5, 'sashimi': 4, 'commentary': 1, 'undoubtedly': 1, 'reminds': 1, 'shop': 2, 'san': 1, 'francisco': 1, 'zero': 6, 'theyd': 1, 'evaluate': 1, 'these': 3, 'jamaican': 1, 'mojitos': 1, 'nearly': 4, 'decide': 1, 'thrilled': 3, 'accommodation': 1, 'vegetarian': 5, 'noted': 1, 'happens': 1, 'plantronics': 4, 'thank': 2, 'wasting': 4, 'consistent': 1, 'boba': 2, 'disgrace': 2, 'ate': 4, 'lunch': 12, 'gyro': 4, 'lettuce': 1, 'only': 2, 'double': 3, 'cheeseburger': 2, 'patty': 1, 'falling': 2, 'uploaded': 1, 'pace': 4, '325': 1, 'cellphone': 2, 'wornout': 1, 'did': 6, 'save': 3, '11': 1, 'biscuit': 5, 'lower': 1, 'pack': 1, 'togo': 1, 'tiramisu': 1, 'cannoli': 1, 'die': 2, 'for': 7, 'duris': 1, 'wholesome': 2, 'appearance': 3, 'total': 5, 'package': 1, 'garbo': 1, 'showed': 3, 'bat': 1, 'silent': 5, 'era': 2, 'netflix': 1, 'stocking': 1, 'attitude': 2, 'attentive': 7, 'given': 8, 'ability': 3, 'strange': 3, 'ticking': 1, 'noise': 4, 'bite': 5, 'refused': 2, 'anymore': 1, 'rest': 7, 'exemplar': 1, 'designer': 1, 'inspiration': 1, 'overcome': 1, 'fear': 4, 'rejection': 1, 'ease': 3, 'result': 4, 'shame': 2, 'treat': 4, 'anthony': 1, 'quinn': 2, 'crazy': 6, 'horse': 1, 'bug': 2, 'climbing': 1, 'kitchen': 2, 'cable': 8, 'flimsy': 2, 'scary': 2, 'canada': 2, 'aye': 1, 'tartar': 1, 'ironically': 1, 'mostly': 6, 'spring': 3, 'roll': 6, 'yummy': 7, 'portrait': 1, 'outside': 10, 'display': 3, 'saving': 1, 'stuck': 1, 'max': 1, 'mute': 1, 'steer': 1, 'genuine': 2, 'palm': 5, 'replacementr': 1, 'pen': 1, 'threepack': 1, 'slim': 2, 'annoying': 6, 'quickly': 8, 'unwatchable': 1, 'dedicated': 1, 'tea': 6, 'jenni': 1, 'buldogis': 1, 'gourmet': 1, '10+': 2, 'slowmoving': 1, 'aimless': 1, 'distressed': 1, 'drifting': 1, 'yes': 4, 'functionality': 2, 'ground': 1, 'large': 7, 'smeared': 1, 'beensteppedinandtrackedeverywhere': 1, 'pile': 2, 'bird': 1, 'poop': 1, 'good4': 1, 'tungsten': 1, 'e2': 1, 'in': 4, 'crumby': 1, 'tasteless': 6, 'plantain': 1, 'wild': 2, 'giallo': 2, 'ton': 1, 'filmsomething': 1, 'granted': 1, 'crowd': 5, 'pleaser': 1, '1928': 1, 'spaghetti': 1, 'continuously': 1, 'bertolucci': 1, 'narrative': 3, 'engaging': 1, 'master': 3, 'aailiyah': 1, 'akasha': 1, 'compelling': 2, 'her': 1, 'entrance': 1, 'mini': 1, 'dance': 2, 'isâwas': 1, 'then': 3, 'proceeding': 2, 'remotely': 1, 'america': 2, 'chipotle': 1, 'julian': 1, 'fellowes': 1, 'triumphed': 1, 'unconvincing': 3, 'cardboard': 2, 'blandly': 1, 'edward': 1, 'chodorov': 1, 'surprisingly': 3, 'directed': 3, 'negulesco': 1, 'update': 1, 'procedure': 2, 'difficult': 6, 'woa': 1, 'waited': 10, 'biographical': 1, 'beyond': 5, 'musician': 1, 'accessory': 1, 'manufacturer': 1, 'setup': 3, 'smoothly': 1, 'thirty': 1, 'seated': 5, 'although': 8, 'vacant': 1, 'hey': 1, 'pleasantly': 1, 'suprised': 1, 'updatewent': 1, 'brunch': 3, 'fail': 3, 'worry': 2, 'blandest': 1, 'indian': 3, 'cuisine': 1, 'visually': 2, 'collect': 1, 'extant': 1, 'austen': 1, 'poorly': 6, 'constructed': 3, 'refill': 2, 'struggle': 1, 'wave': 1, 'embarassing': 1, 'push': 2, 'close': 6, 'tempo': 1, 'prepare': 1, 'bare': 1, 'gloveseverything': 1, 'deep': 1, 'oil': 1, 'favor': 2, 'paid': 4, 'downtown': 3, 'flatlined': 1, 'excuse': 4, 'dumb': 1, 'established': 1, 'zombiestudents': 1, 'removing': 2, 'necklace': 1, 'containing': 1, 'meteorite': 1, 'angus': 1, 'scrimm': 1, 'somewhat': 4, 'gently': 1, 'menacing': 1, 'violinplaying': 1, 'anatomist': 1, 'doctor': 2, 'currently': 1, 'firstperson': 1, 'shooter': 1, 'delay': 1, 'bitpim': 1, 'a': 2, 'program': 1, 'internetto': 1, 'transfer': 2, 'data': 5, 'phonethe': 1, 'reheated': 1, 'ok': 5, 'wedge': 1, 'soggy': 3, 'mindbendingly': 1, 'visual': 3, 'so': 4, 'shed': 2, 'legendary': 1, 'fucking': 1, 'seller': 4, 'understanding': 2, 'patient': 1, 'achille': 1, 'philippa': 1, 'sing': 1, 'duet': 2, 'don': 1, 'giovanni': 1, 'describes': 1, 'situation': 3, 'appreciate': 1, 'layer': 1, 'unhappy': 2, 'angle': 4, 'party': 7, 'clearly': 4, 'establishment': 4, 'assure': 2, 'ipod': 3, 'sum': 1, 'breeder': 1, 'cheaply': 2, 'horror': 5, 'avoided': 3, 'ebola': 1, 'virus': 1, 'thoughtprovoking': 1, 'heard': 4, 'except': 2, 'cole': 2, 'buyit': 1, 'yum': 2, 'eel': 1, 'spicy': 11, 'mayowell': 1, 'none': 9, 'construction': 3, 'mac': 1, 'routine': 1, 'factbased': 1, 'drama': 5, 'boost': 2, 'grate': 1, 'nerve': 1, 'four': 3, 'shirt': 1, 'vibe': 5, 'letting': 3, 'imdb': 1, 'negative': 3, 'otto': 1, 'welcome': 1, 'navigate': 1, 'recessed': 1, 'doe': 3, 'greater': 1, 'promptly': 2, 'greeted': 2, 'joint': 2, 'suggestion': 1, 'wit': 1, 'dropping': 2, 'martini': 1, 'venturing': 1, 'strip': 5, 'aggravating': 1, 'jerk': 2, 'within': 6, 'promised': 1, 'timeframe': 2, 'puff': 1, 'smoke': 3, 'pay': 9, 'telephone': 2, 'repair': 1, 'reaction': 2, 'bitchy': 1, 'bos': 1, 'truly': 8, 'multiple': 3, 'inflate': 1, 'smaller': 1, 'grow': 1, 'rapidly': 1, 'manna': 1, 'heaven': 1, 'predictable': 8, 'unpredictable': 2, 'barking': 1, 'mad': 2, 'witty': 2, 'adaptation': 1, 'dr': 1, 'seuss': 1, 'book': 4, 'brilliantly': 1, 'animated': 1, 'upas': 1, 'finest': 1, 'deserving': 2, 'academy': 1, 'award': 2, 'jerky': 2, 'movement': 1, 'wouldve': 2, 'godfather': 1, 'upload': 1, 'ringtones': 4, 'aside': 2, 'lead': 5, 'debit': 1, 'northern': 1, 'humour': 2, 'positive': 2, 'community': 1, 'represents': 1, 'war': 3, 'italian': 4, 'reviewer': 4, 'called': 4, 'remember': 5, 'sens': 2, 'assaulted': 1, 'strident': 1, 'cord': 1, 'blare': 1, 'warning': 5, 'meaning': 3, 'distinction': 1, 'journey': 3, 'finale': 1, 'possibly': 2, 'faceplate': 1, 'elegant': 2, 'cinematographyif': 1, 'thatsucked': 1, 'unconditional': 1, 'brain': 1, 'shutdown': 1, 'primal': 1, 'impulse': 1, 'selfpreservation': 1, 'stood': 1, 'awkwardly': 2, '510': 3, 'needle': 4, 'paired': 2, '700w': 1, 'skype': 2, 'pc': 4, 'usb': 3, 'transceiver': 1, 'hybrid': 1, 'palmtopcameracellphone': 1, 'excels': 1, 'sooooo': 1, 'regrettably': 1, 'fails': 5, 'horrified': 1, 'sympathetic': 1, 'cutting': 1, 'edge': 3, 'hospitality': 1, 'industry': 2, 'paradise': 1, 'valley': 2, 'refrained': 1, 'recommending': 1, 'cibo': 1, 'tmobile': 4, 'anywhere': 1, 'firehouse': 1, 'superlative': 1, 'imaginable': 2, 'idiotsavant': 1, 'okay': 1, 'consider': 4, 'fair': 2, 'critic': 1, 'duethe': 1, 'creature': 1, 'actually': 14, 'rubber': 1, 'ahead': 1, 'kept': 11, 'warmer': 1, 'yama': 1, 'reccomendation': 1, 'relative': 1, 'europe': 1, 'asia': 1, '12': 9, 'mega': 1, 'pixel': 1, 'good7': 1, '80': 2, 'prettier': 1, 'be': 2, 'graphic': 5, 'sharp': 3, 'mail': 1, 'backlight': 1, 'translating': 1, '5year': 2, 'forever': 6, 'overly': 3, 'replaceeasy': 1, 'operate': 2, 'shelf': 1, 'usable': 1, 'pda': 2, 'realworld': 1, 'useful': 1, 'neat': 3, 'gadget': 2, 'iced': 1, 'actingeven': 1, 'professional': 4, 'debbie': 1, 'rochonwas': 1, 'contributory': 1, 'former': 1, 'dialog': 3, 'chimplike': 1, 'tolerable': 1, 'screenthis': 1, 'software': 7, 'interface': 1, 'decade': 1, 'compete': 1, 'pleather': 1, 'wife': 8, 'lobster': 4, 'bisque': 2, 'soup': 7, 'lukewarm': 2, 'voyage': 1, 'selfdiscovery': 1, 'anyways': 1, 'filling': 2, 'steep': 1, 'file': 1, 'browser': 1, 'offer': 8, 'needshandsfree': 1, 'competent': 1, 'jerry': 1, 'falwell': 1, 'commercial': 2, 'misleading': 1, 'grandmother': 1, 'roasted': 2, 'factor': 1, 'putting': 4, 'major': 1, 'flaw': 6, 'destroy': 1, 'latifas': 1, 'gem': 3, 'term': 2, 'screenplay': 1, 'postproduction': 1, 'editing': 6, 'filmmaking': 2, 'equally': 5, 'rare': 6, 'pink': 1, 'aerial': 3, 'welldone': 1, 'matthew': 1, 'wrotedirected': 1, '1995': 1, 'monster': 2, 'grim': 1, 'attached': 1, 'gas': 2, 'a+': 1, 'described': 2, 'bargain': 5, 'overwhelmed': 2, 'stayed': 2, 'campy': 1, 'sort': 2, 'seperated': 1, 'mere': 1, '5+': 1, 'ft': 1, 'notice': 2, 'excessive': 1, 'static': 3, 'garbled': 1, 'stewart': 1, 'hero': 2, 'rip': 2, 'climax': 1, 'embassy': 1, 'brooding': 1, 'menace': 1, 'lowbudget': 1, 'shenanigan': 1, 'surrounding': 1, 'murdered': 2, 'spy': 1, 'kidnapped': 1, 'foreign': 1, 'random': 1, 'taxidermist': 1, 'clever': 4, 'crowdpleaserthis': 1, 'rank': 3, 'wouldnt': 1, 'translate': 1, 'hungry': 1, 'stuffed': 2, 'letdown': 1, 'camelback': 1, 'flower': 3, 'cartel': 1, 'kill': 1, 'momentum': 1, 'quicker': 1, 'purcashed': 1, 'excelent': 1, 'exquisite': 3, 'egg': 6, 'favorite': 4, 'shower': 2, 'rinse': 1, 'nude': 1, 'ticket': 1, 'five': 3, '750': 1, 'seasoned': 3, 'extended': 2, 'electronics': 1, 'available': 1, 'fm': 1, 'transmitter': 1, 'bela': 1, 'lugosi': 1, 'extraneous': 1, 'intoning': 1, 'odd': 3, 'toon': 1, 'delivered': 1, 'popular': 2, 'underrated': 1, 'immediately': 5, 'attention': 4, 'waterproof': 1, '2mp': 1, 'pic': 1, 'parent': 3, 'similar': 2, 'silently': 1, 'att': 2, 'distorted': 1, 'yell': 1, 'inexcusable': 1, 'returning': 4, 'carrier': 1, 'modern': 3, 'genius': 2, 'passion': 1, 'taking': 1, 'disapointing': 1, '350': 1, 'jabra350': 1, 'national': 1, 'treasure': 1, 'regular': 4, 'renowned': 1, 'screenwriter': 2, 'france': 1, 'marion': 1, 'starring': 1, 'jaclyn': 1, 'smith': 1, 'god': 3, 'sold': 1, 'bipolarity': 1, 'ruthless': 3, 'thug': 1, 'luvs': 1, 'diaper': 1, 'awkward': 2, 'rotating': 3, 'mouse': 1, 'following': 2, 'plane': 1, 'filmmostly': 1, 'groundbreaking': 1, 'my': 4, 'brother': 2, 'thiswhen': 1, 'robert': 2, 'ryan': 1, 'type': 3, 'imitation': 1, 'individual': 1, 'shrimp': 7, 'moist': 5, 'situations1': 1, 'interest': 1, 'expression': 1, 'celebration': 1, 'patriotism': 1, 'underline': 1, 'bachi': 2, 'recommendation': 4, 'muffled': 1, 'incoming': 1, 'severe': 1, 'echo': 2, 'protects': 1, 'omit': 1, 'entirely': 2, 'vegetable': 6, 'thai': 6, '810': 1, 'unneeded': 1, 'controversy': 1, 'sat': 8, 'riveted': 1, 'grtting': 1, '744': 1, 'v3c': 1, 'filmography': 1, 'site': 2, 'chance': 1, 'latest': 1, 'o': 1, 'v115g': 1, 'crawl': 1, 'walkman': 1, 'bathroom': 7, 'finished': 2, 'accident': 1, 'satisfying': 3, 'flash': 2, 'randomly': 1, 'pocket': 4, 'locked': 1, 'massive': 4, 'unlockable': 1, 'sloppy': 1, 'crackle': 1, 'youthful': 1, 'energy': 4, 'follow': 2, 'concentrate': 1, 'meander': 1, 'badly': 2, 'experiencing': 1, 'underwhelming': 3, 'person': 4, 'handed': 1, 'listed': 1, 'exercise': 1, 'derivative': 1, 'mercy': 2, 'killing': 2, 'evidently': 1, 'limited': 2, 'weekend': 1, 'iq': 2, 'mollusk': 1, 'existing': 1, 'cd': 1, 'appalling': 3, 'hardest': 1, 'm': 2, 'taped': 1, 'realised': 1, 'lewis': 1, 'considerable': 1, 'incendiary': 1, 'unrestrained': 1, 'baby': 3, 'owl': 1, 'ie': 2, 'coverage': 3, 'pitch': 1, 'reflected': 1, 'belowpar': 1, 'borrowed': 1, 'hypocrisy': 1, 'vomit': 1, 'beginning': 4, 'coach': 1, 'fascinating': 2, 'mandalay': 1, 'omelet': 1, 'phenomenal': 2, 'opinion': 2, 'warmth': 2, 'tragedy': 1, 'struck': 3, 'morgan': 2, 'equivalent': 1, 'dickens': 1, 'christmas': 5, 'carol': 1, 'sensibility': 1, 'lazy': 1, 'himself': 1, 'besides': 1, 'costcos': 1, 'transformed': 1, 'organizational': 1, 'capability': 1, 'easier': 4, 'enter': 2, 'admins': 1, 'brand': 2, 'howeverthe': 1, 'riingtones': 1, 'neither': 4, 'seafood': 6, 'string': 2, 'bottom': 2, '15lb': 1, 'cow': 2, '34ths': 1, 'gristle': 1, 'fat': 3, 'inhouse': 1, 'shouting': 1, 'outstanding': 3, 'taco': 8, 'install': 2, 'looking': 12, 'frustrated': 1, 'missing': 1, 'outperform': 1, 'china': 1, 'v325i': 1, 'ribeye': 1, 'mesquite': 1, 'your': 1, 'dvd': 3, 'halfway': 1, 'embarrassed': 1, 'howell': 1, 'onid': 1, 'avoiding': 1, 'drained': 1, 'dying': 2, 'integrated': 1, 'seamlessly': 2, 'timely': 1, 'shipment': 1, '50': 2, 'drain': 4, 'highlight': 4, 'nigiri': 1, 'applauded': 1, 'boyfriend': 5, 'lemon': 1, 'raspberry': 1, 'cocktail': 2, 'receiving': 2, 'respect': 1, 'stunning': 3, 'fx': 2, 'stateoftheart': 1, 'muddy': 1, 'casing': 1, 'insert': 1, 'glued': 1, 'slid': 1, 'panna': 1, 'cotta': 1, 'mid': 3, 'wrapped': 1, 'originality': 1, 'freshness': 1, 'bose': 1, 'cancelling': 1, 'nyc': 2, 'commuter': 1, 'insipid': 1, 'cause': 4, 'regret': 3, 'tongue': 2, 'cheek': 2, 'biggest': 4, 'superfast': 1, 'fleshed': 1, 'grime': 1, 'blake': 1, 'deliver': 2, 'scripted': 1, 'deadpan': 1, 'hilarious': 6, 'known': 3, 'dad': 1, 'grew': 1, 'linked': 1, 'weaker': 1, 'investment': 1, 'law': 1, 'mall': 2, 'sick': 7, 'ben': 1, 'affleck': 1, 'sandra': 1, 'bullock': 1, 'leaving': 1, 'wifetobe': 1, 'chick': 2, 'knocked': 1, 'by': 1, 'olive': 1, 'iam': 1, 'happening': 1, 'stop': 4, 'crawfish': 1, 'voodoo': 1, 'gluten': 1, 'vivian': 1, 'schilling': 1, 'lifetime': 1, 'air': 1, 'sell': 1, 'musthave': 1, 'joeys': 1, 'voted': 1, 'reader': 1, 'phoenix': 5, 'magazine': 1, 'packaged': 3, 'liking': 1, 'reviewing': 1, 'handmade': 1, 'fundamental': 1, 'legal': 1, 'process': 2, 'discovering': 1, 'guilt': 1, 'innocence': 1, 'present': 2, 'court': 3, 'disliked': 2, 'despised': 1, 'personality': 1, 'twist': 3, 'occur': 1, 'garfield': 1, 'ann': 1, 'revere': 1, 'lilli': 1, 'plmer': 1, 'william': 1, 'conrad': 1, 'leeand': 1, 'filmed': 2, 'greatest': 4, 'cinematographer': 1, 'screenjames': 1, 'wong': 1, 'howe': 1, 'shoe': 1, 'goat': 1, 'skimp': 1, 'jewel': 1, 'la': 2, 'hoping': 3, 'ten': 4, 'squib': 1, '2007': 1, 'crash': 1, 'provokes': 1, 'teach': 1, 'racism': 1, 'prejudice': 1, 'glove': 1, 'secure': 2, 'durable': 1, 'mouthful': 1, 'relaxed': 1, 'venue': 1, 'group': 3, 'scare': 2, 'tension': 3, 'medical': 1, 'terminology': 1, 'iffy': 1, 'insulin': 1, 'dependant': 1, 'diabetic': 1, 'myself': 2, 'involved': 3, 'school': 1, 'round': 3, 'providing': 1, 'trouble': 3, 'accessing': 1, 'downloading': 1, 'performing': 1, 'accountant': 1, 'screwed': 1, 'sci': 1, 'fi': 1, 'antena': 1, 'start': 4, 'problemsâthe': 1, 'professor': 1, 'structure': 1, 'tightly': 1, 'understatement': 1, 'length': 1, 'min': 3, 'milkshake': 1, 'chocolate': 1, 'milk': 1, 'disrespected': 3, 'laugh': 3, 'once': 4, 'amazed': 3, 'shawarrrrrrma': 1, 'drastically': 1, 'cheaper': 2, 'horrendous': 1, 'frog': 1, 'catching': 2, 'ample': 2, 'plan': 4, 'june': 2, 'allison': 1, 'improved': 1, 'improvisation': 1, 'whether': 6, 'delivering': 1, 'southern': 1, 'california': 1, 'desert': 1, 'patent': 1, 'documentary': 5, 'watkins': 2, 'creates': 2, 'sleek': 2, 'practical': 2, 'storage': 2, 'blanket': 1, 'moz': 1, 'subpar': 2, 'th': 1, 'showcasing': 1, 'noteworthy': 2, 'initially': 1, 'local': 1, 'buffalo': 1, 'intrigued': 1, 'wearing': 2, 'hat': 1, 'debated': 1, 'sack': 1, 'trumpeter': 1, 'falsely': 1, 'accused': 1, 'murder': 1, 'stopped': 3, 'latch': 1, 'visor': 1, 'ryans': 2, 'portrayed': 1, 'someone': 10, 'father': 3, 'schizophrenic': 1, 'lifemy': 1, 'affected': 1, 'thomerson': 1, 'james': 1, 'surprise': 3, 'lightweight': 4, 'seat': 3, 'afraid': 2, 'mic': 4, 'genuinely': 1, 'enthusiastic': 1, 'ridiculous': 7, 'negligent': 1, 'unwelcome': 1, 'suggest': 1, 'surroundings': 1, 'sergeant': 1, 'pepper': 1, 'auju': 1, 'securly': 1, 'belt': 5, 'psychological': 2, 'detailing': 1, 'loyalty': 1, 'treachery': 1, 'docking': 2, 'fifteen': 2, 'um': 1, 'grab': 1, 'pub': 1, 'bud': 1, 'accomodate': 1, 'veganveggie': 1, 'gerardo': 1, 'overnight': 1, 'alarm': 1, 'clock': 1, 'accompanied': 1, 'suffered': 1, 'mood': 2, 'restored': 1, 'vinegrette': 3, 'snow': 1, 'finish': 3, 'noodle': 1, 'drag': 2, 'waaay': 1, 'death': 2, 'row': 2, 'unmoving': 1, 'nicolas': 1, 'roeg': 1, 'wih': 1, 'explanation': 2, 'atrocity': 1, 'ripped': 3, 'banana': 1, 'petrified': 1, 'according': 1, 'applifies': 1, 'underwater': 1, 'repeated': 1, 'thousand': 1, '40min': 1, 'ordering': 2, 'arriving': 1, 'busy': 4, 'balanced': 1, 'underacting': 1, 'doubt': 2, 'acknowledged': 2, 'hollow': 2, 'shell': 1, 'success': 1, 'depends': 1, 'sydney': 1, 'greenstreet': 1, 'yardley': 1, 'onethis': 1, 'casted': 1, 'ready': 4, 'team': 1, 'behind': 4, 'continue': 3, 'own': 1, 'hi': 1, 'bussell': 1, 'sprout': 1, 'risotto': 1, 'filet': 2, 'salt': 4, 'pepperand': 1, 'upstairs': 1, 'basement': 1, 'shield': 1, 'incrediable': 1, 'pap': 1, 'screened': 1, 'afternoon': 2, 'punish': 1, 'unemployed': 1, 'sequel': 1, 'including': 3, 'view': 2, 'barcelona': 1, 'famed': 1, 'gaudi': 1, 'tower': 1, 'should': 1, 'premise': 4, 'nutbag': 1, 'stephen': 1, 'mchattie': 1, 'lance': 1, 'hendrikson': 1, 'flick': 5, 'raging': 1, 'cheekbone': 1, 'boiled': 1, 'crab': 2, 'leg': 2, 'inexperience': 1, 'meant': 1, 'dramatic': 2, 'conflict': 2, 'disappoint': 3, 'pairing': 3, 'periodically': 1, 'somehow': 2, 'meatloaf': 1, 'crispy': 1, 'tuna': 3, 'melt': 4, 'sappiest': 1, 'displeased': 1, 'exchanged': 2, 'bartender': 4, 'personable': 1, 'simplifying': 1, 'sake': 2, 'brevity': 1, 'core': 2, 'fulfilling': 1, 'frankly': 2, 'cotton': 1, 'club': 3, 'unfaithful': 1, 'gere': 1, 'join': 3, 'revenge': 1, 'boogeyman': 1, 'zombiez': 1, 'hellish': 1, 'trinity': 1, 'methe': 1, 'toro': 1, 'tartare': 1, 'cavier': 1, 'thinly': 1, 'sliced': 3, 'wagyu': 1, 'truffle': 1, 'figured': 1, 'publicly': 1, 'loudly': 1, 'earpad': 1, 'onlyi': 1, 'luck': 2, 'noncustomer': 1, 'sexy': 1, 'outrageously': 1, 'flirting': 1, 'hottest': 1, 'costars': 1, 'freeman': 1, 'ed': 2, 'helm': 1, 'adapter': 2, 'hardly': 2, 'hiro': 1, 'european': 1, 'throwback': 1, 'student': 1, '1980s': 1, 'abroad': 1, 'interacting': 1, 'nationality': 1, 'circumstance': 3, 'slightly': 1, 'live': 6, 'friday': 1, 'blow': 2, 'psyched': 1, 'appointment': 1, 'astronaut': 2, 'considers': 1, 'crashed': 2, 'ussr': 1, 'decor': 4, 'piano': 1, 'mobile': 2, 'absolutley': 1, 'promise': 2, 'gel': 2, 'r': 2, 'explosion': 1, 'tank': 1, 'tigerlilly': 1, 'razor': 1, 'v3i': 1, 'refuse': 1, 'refund': 3, 'aluminum': 1, 'vx': 1, 'wellit': 1, 'protected': 1, 'handheld': 1, 'dit': 1, '5320': 1, 'video': 4, 'veggitarian': 1, 'platter': 1, 'deserves': 4, 'nine': 1, 'despicable': 1, 'toasted': 3, 'english': 2, 'muffin': 1, 'untoasted': 1, 'earpiece': 7, 'colleague': 1, 'receptiona': 1, 'disagree': 1, 'fellow': 1, 'yelpers': 1, '2160': 1, 'tracfone': 1, 'television': 1, 'stereotype': 2, 'offend': 1, 'strength': 1, 'hip': 1, 'maintaining': 1, 'coziness': 1, 'despite': 6, 'pan': 2, 'ambiance': 9, 'improper': 1, 'tracfonewebsite': 1, 'toactivate': 1, 'copier': 1, 'significant': 3, 'themeat': 1, 'wouldbe': 1, 'undertone': 1, 'fifty': 1, 'existential': 1, 'worldweariness': 1, 'ought': 1, 'deeply': 3, 'daily': 1, 'greatno': 1, 'yawn': 1, 'shameful': 1, 'spinach': 1, 'avocado': 1, 'ingredient': 1, 'sad': 5, 'nevertheless': 1, 'stable': 1, 'succeeds': 1, 'meagre': 1, 'similarly': 1, 'delivery': 2, 'apology': 1, 'accessoryone': 1, 'development': 2, 'lacked': 8, 'serf': 2, 'handsdown': 1, 'metro': 2, 'feelgood': 1, 'trunk': 1, 'carried': 1, 'hitch': 1, 'stick': 4, 'malta': 1, 'setting': 9, 'barren': 1, 'reset': 1, 'wiping': 1, 'mode': 1, 'edinburgh': 1, 'revisiting': 1, 'magical': 1, 'handsfree': 3, 'acceptable': 1, 'andddd': 1, '70+': 1, 'claimed': 1, 'had': 9, 'vitally': 1, 'occurs': 1, 'planned': 1, 'dodge': 1, 'stratus': 1, 'maker': 1, 'restrained': 1, 'quãbec': 1, 'tapa': 3, 'potted': 1, 'plant': 1, 'batter': 2, 'chewy': 4, 'penny': 1, 'youtube': 1, 'wallet': 1, 'walk': 1, 'theatre': 2, 'relief': 1, 'click': 1, 'mechanism': 1, 'simpler': 1, 'alone': 3, 'def': 1, 'nobody': 3, 'identifies': 1, 'cutout': 2, 'predictably': 2, 'reversestereotypes': 1, 'christopher': 1, 'eccleston': 1, 'control': 4, 'tardis': 1, 'continuation': 1, 'slacker': 1, 'muststop': 1, 'cashier': 2, 'wayyy': 1, '23': 2, 'source': 2, 'revealing': 2, 'cape': 1, 'cod': 1, 'ravoli': 1, 'chickenwith': 1, 'cranberrymmmm': 1, 'oyvey': 1, 'couldnt': 1, 'earphone': 2, 'terribly': 2, 'summarize': 1, 'nay': 1, 'transcendant': 1, 'brings': 2, 'pneumatic': 1, 'condiment': 1, 'dispenser': 1, 'subtitle': 1, 'aversion': 1, 'therapy': 1, 'research': 1, 'division': 1, 'doing': 1, 'ideal': 1, 'whose': 1, 'sensitive': 1, 's11': 1, 'universe': 1, 'aired': 1, 'dribble': 1, 'noncliche': 1, 'predict': 1, 'verbatim': 1, 'accent': 1, 'abysmal': 1, 'just': 1, 'sun': 1, 'convention': 1, 'hatred': 1, 'clichãs': 2, 'admitted': 1, '2000': 1, 'maintain': 2, 'monkey': 1, 'share': 3, 'dna': 1, 'copy': 1, 'rpg': 1, 'selfrespecting': 1, 'rpger': 1, '6': 4, 'counter': 1, 'crackedi': 1, 'laughing': 1, 'sam': 1, 'shepard': 1, 'gung': 1, 'ho': 1, 'marine': 1, 'sobering': 1, 'considered': 1, 'apt': 1, 'stanwycks': 1, 'singing': 3, 'describing': 1, 'tepid': 1, 'usually': 2, 'headband': 1, 'stomach': 5, 'ache': 1, 'rubberpetroleum': 1, 'unbearable': 2, 'caused': 2, 'corded': 1, 'geek': 1, 'bible': 1, 'thumper': 1, 'badass': 1, 'traditional': 1, 'hunan': 1, 'carrell': 1, 'builder': 1, 'cross': 1, 'g': 1, 'pg': 1, 'neighborhood': 2, 'interior': 1, 'ratio': 1, 'unsatisfying': 1, 'madhouse': 1, 'access': 2, 'instance': 1, 'wed': 1, 'punishment': 1, 'park': 1, 'wirefly': 1, 'stari': 1, 'cingularatt': 1, 'inform': 1, 'practice': 1, 'slowly': 1, 'cake': 1, 'raving': 1, 'sugary': 2, 'tailored': 1, 'palate': 1, 'informative': 1, 'complexity': 1, 'task': 1, 'challenge': 1, 'facing': 1, 'south': 2, 'africa': 2, 'receive': 2, 'accolade': 1, 'outta': 1, 'zillion': 1, 'reality': 1, 'personally': 2, 'involving': 1, 'freeze': 1, 'frequently4': 1, 'louder': 1, 'speaker': 3, 'size': 5, 'footage': 3, 'elderly': 1, 'babbling': 1, 'overwrought': 1, 'pseudosatanic': 1, 'gibberish': 1, 'corny': 1, 'teen': 1, 'goth': 1, 'blush': 1, 'olde': 1, 'latin': 1, 'flip': 3, 'whistle': 1, 'composition': 2, 'inventive': 1, 'lighting': 3, 'pointillistic': 1, 'behold': 1, 'upgrade': 1, 'discount': 2, 'courteous': 1, 'reversible': 1, 'as': 1, 'uncalled': 1, 'shouldve': 1, 'invented': 1, 'sooner': 1, 'ups': 2, 'down': 4, 'knew': 3, 'miss': 2, 'pillow': 1, 'girlfriendboyfriend': 1, 'occupied': 3, 'gooodd': 1, 'bluetooths': 1, 'listener': 1, 'stereo': 1, 'concert': 1, 'sequence': 2, 'contains': 1, 'cheesiness': 1, 'unethical': 1, 'rated': 5, 'nc17': 1, 'punched': 1, 'gallon': 1, 'spew': 1, 'after': 1, 'absolutel': 1, 'perpared': 1, 'presentation': 3, 'giant': 1, 'slice': 1, 'toast': 2, 'lightly': 2, 'dusted': 1, 'powdered': 1, 'sugar': 1, 'grilled': 2, 'reminded': 1, 'legit': 2, 'handling': 1, 'rowdy': 1, 'experienced': 3, 'p': 1, 'blown': 2, 'efficient': 1, 'body': 1, 'soul': 2, '1947': 1, 'bmw': 1, 'quiet': 2, 'hearing': 1, 'saying': 4, 'cat': 1, 'attacked': 1, 'protective': 1, 'destroying': 1, 'weekly': 1, 'haunt': 1, 'inspiring': 1, 'proud': 1, 'mature': 1, 'suggests': 1, 'focus': 2, 'underlying': 2, 'inappropriate': 1, 'smiling': 1, 'keira': 1, 'knightley': 1, 'prone': 1, 'rita': 1, 'hayworth': 1, 'pedestal': 1, 'exceptional': 2, 'atmosphere1': 1, 'prime': 2, 'rib': 1, 'section': 1, 'scallop': 2, 'bethe': 1, 'ca42': 1, 'replaced': 1, 'comfortably': 4, 'fo': 1, 'trimmed': 1, 'deaf': 1, 'petty': 1, 'jim': 1, 'oconnor': 1, 'energetic': 1, 'george': 1, 'dull': 2, 'az': 1, 'connoisseur': 1, 'sorely': 1, 'insane': 1, 'sudden': 1, 'defective': 2, 'excalibur': 1, 'common': 1, 'madison': 1, 'ironman': 1, 'door': 5, 'florida': 1, 'victor': 1, 'mclaglen': 1, 'brian': 2, 'donlevy': 1, 'chill': 1, 'regardless': 1, 'hence': 2, 'title': 1, 'whine': 2, 'goesthe': 1, 'wordofmouth': 1, 'promote': 1, 'beauty': 1, 'diverse': 1, 'specially': 1, 'eclectic': 1, '1973': 1, 'fly': 2, 'apple': 1, 'juice': 1, 'where': 1, 'identify': 1, 'sean': 1, 'connerys': 1, 'noble': 1, 'brigand': 1, 'candace': 1, 'bergen': 1, 'feisty': 1, 'heroine': 1, 'huston': 1, 'wily': 1, 'hay': 1, 'steve': 3, 'kanalys': 1, 'spiffy': 1, 'radiant': 1, 'cando': 1, 'lieutenant': 1, 'roosevelt': 1, 'allows': 2, 'connect': 1, 'miniusb': 1, 'forgetting': 2, 'highquality': 1, 'caesar': 1, 'composed': 1, 'eyed': 1, 'pea': 1, 'unreal': 1, 'ridiculousness': 1, 'muppets': 1, 'brick': 3, 'oven': 3, 'app': 1, 'steiner': 1, 'startac': 1, 'regretted': 1, 'potentially': 1, 'manages': 1, 'transcend': 1, 'limitation': 1, 'indie': 1, 'continually': 1, 'subverting': 1, 'expectation': 3, 'emerge': 1, 'intense': 1, 'widmark': 1, 'unintentionally': 1, 'comical': 1, 'arepas': 1, 'cg': 1, 'opening': 1, 'microsoft': 1, 'slideshow': 1, 'smallest': 1, 'doomed': 1, 'conception': 1, 'humiliated': 1, 'worker': 3, 'mebunch': 1, 'name': 1, 'calling': 1, 'complained': 1, 'photography': 2, 'searched': 1, 'study': 2, 'interested': 3, 'sin': 1, 'industrial': 1, 'fingernail': 1, 'chalkboard': 1, 'recharge': 2, 'frequentyly': 1, 'phones2': 1, 'edible': 4, 'ngage': 1, 'earbuds': 1, 'background': 2, 'distracting': 1, 'realize': 1, 'occasion': 1, 'medium': 2, 'bloodiest': 1, 'plate': 2, 'bold': 2, 'reenactment': 1, 'emotionally': 1, 'adrift': 1, 'stagy': 1, 'headoverheels': 1, 'key': 2, 'pad': 2, 'lit': 1, 'ergonomic': 1, 'theory': 1, 'stand': 2, 'disturbing': 1, 'succeeded': 1, 'prompt': 2, 'numerous': 2, 'proudly': 1, 'classical': 1, 'wb': 1, 'gripping': 2, 'crocdodile': 1, 'believed': 1, 'crocs': 1, 'swamp': 1, 'fabulous': 4, 'lox': 1, 'caper': 1, 'interview': 1, 'vampire': 1, 'lestat': 1, 'stuart': 1, 'townsend': 1, 'cruise': 1, 'h500': 1, 'impossible': 1, 'par': 3, 'hello': 1, '18th': 1, 'jutland': 1, 'instrument': 1, 'crack': 1, 'early': 3, 'future': 2, 'goremeister': 1, 'lucio': 1, 'fulci': 1, 'subgenre': 1, 'attractive': 2, 'eyepleasing': 1, 'calendar': 1, 'sync': 1, 'nonlinear': 1, 'narration': 1, 'thus': 2, 'flashback': 1, 'articulated': 1, 'via': 3, 'loosely': 1, 'moviegoing': 1, 'itll': 1, '70': 2, 'grainy': 1, 'enhanced': 1, 'meredith': 1, 'nobu': 1, 'delivers': 3, 'trythe': 1, 'engineered': 1, 'tonight': 2, 'elk': 1, 'specialand': 1, 'wedding': 1, 'brought': 4, 'frozen': 3, 'margarita': 2, 'presence': 2, 'shined': 1, 'senior': 1, 'poetry': 2, 'politics': 1, 'japanese': 3, 'stage': 3, 'theatrical': 1, 'everyones': 1, 'terror': 1, 'escalating': 1, 'monstrous': 1, 'consequence': 1, 'welldesigned': 1, 'relate': 1, 'hell': 3, 'understated': 2, 'impression': 1, 'ventilation': 1, 'upgrading': 1, 'magnificent': 1, 'photographycinematography': 1, 'compliment': 3, 'resounding': 1, '9': 1, 'dripping': 1, 'coconut': 1, 'thinking': 3, 'sliding': 1, 'pant': 1, 'bloody': 1, 'mary': 2, 'count': 1, 'majority': 1, 'logitech': 2, 'earbud': 3, 'failed': 4, 'miserable': 1, 'laughable': 2, 'adventure': 1, 'sour': 3, 'actingwise': 1, 'emptiness': 1, 'hoursthe': 1, 'thereplacement': 1, '95': 1, 'cheesecurds': 1, 'ant': 1, 'possibility': 1, 'booking': 1, 'ayce': 1, 'cingulair': 1, 'nicer': 1, 'contstruct': 1, 'hinge': 1, 'inconspicuous': 1, 'freezing': 1, 'crema': 1, 'café': 1, 'expanded': 1, '3o': 1, 'phonemy': 1, 'replenished': 1, 'plain': 3, 'yucky': 1, 'applause': 1, 'prelude': 1, 'd807wrongly': 1, 'd807': 1, 'entree': 3, 'gc': 1, 'rough': 1, 'draft': 1, 'shooting': 1, 'began': 1, 'completed': 1, 'inconsiderate': 1, 'ohsomature': 1, 'neighbourgirl': 1, 'misplace': 1, 'pissd': 1, 'activated': 1, 'suddenly': 1, 'unacceptableunless': 1, 'improve': 1, 'leak': 1, 'unacceptable': 1, 'soft': 1, 'tight': 1, 'shape': 1, 'weve': 3, 'hole': 2, 'street': 1, 'blew': 2, 'albondigas': 1, 'warm': 9, 'tomato': 1, 'meatball': 1, 'correctly': 1, 'barney': 1, 'de': 2, 'duper': 1, 'painfully': 1, 'dreary': 1, 'timewaster': 1, 'flavourful': 1, 'intention': 1, 'gifted': 1, 'shipped': 2, 'sits': 1, 'soldier': 1, 'masculinity': 1, 'pledge': 1, 'hairsplitting': 1, 'purity': 1, 'admiration': 1, 'sword': 1, 'screamy': 1, 'masculine': 1, 'ticker': 1, 'contacted': 1, 'receipt': 1, 'marriage': 1, 'luke': 1, 'sever': 1, 'wellpaced': 1, 'suited': 1, 'relatively': 2, 'certain': 2, 'move': 2, 'uplifting': 2, 'phonebattery': 1, 'wont': 3, 'colour': 1, 'french': 2, 'flag': 1, 'tracking': 1, 'charismafree': 1, 'melted': 1, 'styrofoam': 1, 'constantly': 1, 'what': 1, 'brokeni': 1, 'smoking': 1, '2006': 1, 'sitdown': 1, 'spicier': 1, 'prefer': 1, 'combo': 3, 'military': 1, 'tying': 1, 'loose': 2, 'paced': 1, 'courtroom': 2, 'baklava': 1, 'falafel': 1, 'baba': 1, 'ganoush': 1, 'relax': 1, 'schoolers': 1, 'cry': 1, 'transmission': 1, 'noircrimedrama': 1, 'belmondo': 1, 'lino': 1, 'ventura': 1, 'krussel': 1, 'indictment': 1, 'justice': 1, 'system': 1, 'sidelined': 1, 'inexplicable': 1, 'crew': 1, 'visited': 1, 'skilled': 1, 'hosting': 1, 'voiceovers': 1, 'monotonous': 1, 'guest': 4, 'convey': 1, 'broad': 1, 'sweep': 1, 'landscape': 1, 'macarons': 1, 'insanely': 1, 'desired': 1, 'possesed': 1, 'content': 1, 'fill': 3, 'nicely': 1, 'damage': 1, 'age': 2, 'college': 1, 'cooking': 1, 'class': 2, 'atrocious': 1, 'girlfriend': 2, 'veal': 1, 'yellowtail': 1, 'carpaccio': 1, 'allowing': 2, '1971': 1, 'format': 1, 'some': 1, 'miniseries': 1, 'baaaaaad': 1, 'armand': 1, 'assante': 1, 'sounded': 3, 'upbeat': 1, 'overdue': 1, 'tale': 2, 'crostini': 1, 'defeat': 1, 'purpose': 1, 'drivng': 1, 'ringing': 2, 'bye': 2, 'animal': 1, 'integration': 1, 'bluegreenscreen': 1, 'linking': 1, '8530': 1, 'blackberry': 2, 'curve': 1, 'converter': 1, 'raw': 1, 'sublimely': 1, 'stink': 1, 'losing': 2, 'melville': 1, 'scream': 2, 'ignore': 1, 'sitcom': 1, 'oriented': 1, 'teenager': 1, 'receives': 1, 'contract': 2, 'rocketed': 1, 'destination': 1, 'unknown': 1, 'cancan': 1, 'boast': 1, 'cutest': 1, 'leading': 1, 'threw': 1, 'window': 2, 'bougth': 1, 'l7c': 1, 'peanut': 3, 'bluetoothmotorola': 1, 'hs850': 1, 'privileged': 1, 'workingeating': 1, 'witnessed': 1, 'crouton': 1, 'frenchman': 1, 'geeky': 1, 'sex': 2, 'ooze': 1, 'embedded': 1, 'stylish': 1, 'simmering': 1, 'boiling': 1, 'wart': 1, 'poet': 1, 'bohemian': 1, 'wartime': 1, 'span': 2, 'bombardment': 1, 'london': 1, 'outward': 1, 'tranquillity': 1, 'welsh': 1, 'coastal': 1, 'retreat': 1, 'borderline': 1, 'friendship': 1, 'lust': 1, 'dedication': 1, 'versus': 2, 'concern': 3, 'jealousy': 1, 'rivalry': 1, 'cowardice': 1, 'egotism': 1, 'heroism': 1, 'selfsacrifice': 1, 'chow': 2, 'mein': 1, 'wanting': 1, 'rich': 1, 'accordingly': 1, 'everywhere': 1, 'regularly': 1, 'unnecessary': 1, 'trainroller': 1, 'coaster': 1, 'worthy': 1, 'syrupy': 1, 'indulgent': 1, 'philadelphia': 1, 'plantronincs': 1, 'continues': 1, 'peaking': 1, 'columbo': 1, 'fix': 1, 'itself': 1, 'cheated': 1, '7': 2, 'arrival': 1, 'fraction': 1, 'open': 2, 'atleast': 1, 'whoever': 1, 'peculiarity': 1, 'exclaim': 1, 'whoa': 1, 'storm': 1, 'trooper': 1, 'list': 6, 'wonderfully': 2, 'garlic': 3, 'bone': 1, 'marrow': 2, 'added': 3, 'forty': 1, 'vain': 1, 'ac': 1, 'included': 4, 'juicehighy': 1, 'conceptually': 1, 'everybody': 1, 'fantasy': 1, 'andor': 1, 'thunderbird': 1, 'infuriating': 1, 'asking': 1, 'unbelievably': 1, 'uninspired': 1, 'inconsistency': 1, 'horrid': 1, 'serving': 3, 'tater': 1, 'tot': 2, 'southwest': 1, 'unrecommended': 1, 'sentiment': 1, 'installed': 1, 'overnite': 1, 'shocked': 1, 'indicate': 1, 'cash': 1, 'starter': 1, 'sensitivity': 1, 'treatment': 1, 'stagey': 1, 'farce': 1, 'web': 1, 'browsing': 1, 'significantly': 1, 'faster': 1, 'excellentangel': 1, 'scamp': 3, 'adorablehis': 1, 'yelp': 1, 'scaredand': 1, 'funniest': 1, 'whenscamp': 1, 'curtain': 1, 'angel': 2, 'beforei': 1, 'movieits': 1, 'edition': 1, '20the': 1, 'lid': 1, 'awarded': 1, 'alongside': 1, 'olivia': 1, 'havilland': 1, 'amazingrge': 1, 'fillet': 1, 'relleno': 1, 'puck': 1, 'disgust': 1, 'register': 1, 'defect': 1, 'risk': 1, 'built': 1, 'superficial': 1, 'itfriendly': 1, 'packed': 1, 'hopefully': 1, 'bodes': 1, 'cook': 3, 'ireland': 1, 'manual': 1, 'romanticcharminghilariousand': 1, 'adorablethe': 1, 'junkyard': 2, 'funnyall': 1, 'specialtoo': 1, 'laughedkids': 1, 'itbuy': 1, 'outit': 1, 'logic': 1, 'theft': 1, 'booksomethats': 1, 'disgraceful': 1, 'hella': 1, 'salty': 1, 'woven': 1, 'splendid': 1, 'writer': 1, 'smack': 1, 'bonus': 1, 'showthese': 1, 'upway': 1, 'actorsan': 1, 'haggis': 1, 'stroke': 1, 'storytellinga': 1, 'painted': 1, 'crayon': 1, 'cheerless': 1, 'heist': 1, 'characterisation': 1, 'underbite': 1, 'stoic': 1, 'emoting': 1, 'yun': 1, 'tomorrow': 1, 'cheesy': 1, 'abandoned': 1, 'factory': 1, 'executed': 1, 'flying': 1, 'judo': 1, 'woo': 1, 'repeating': 1, 'robotic': 1, 'precisely': 1, 'monumental': 1, 'childlike': 1, 'actual': 1, 'relocated': 1, 'timeless': 1, 'bouchon': 1, 'fiancé': 1, 'middle': 1, '13': 2, 'megapixels': 1, 'render': 1, 'image': 1, 'resolution': 2, 'pro': 3, 'prompted': 1, 'swung': 1, 'hankering': 1, 'blueant': 1, 'supertooth': 1, 'rightthe': 1, 'velvet': 1, 'cakeohhh': 1, 'iphone': 3, 'connecting': 1, 'imac': 1, 'external': 1, 'confuses': 1, 'vomited': 3, 'bus': 1, 'overcooked': 2, 'pulling': 1, 'attempting': 1, 'artiness': 1, 'became': 1, 'nonexistent': 1, 'charisma': 1, 'comedic': 1, 'timing': 1, 'heavyit': 1, 'martin': 1, 'middleaged': 1, 'upper': 1, 'uptight': 1, 'windresistant': 1, 'witticism': 1, '17': 1, 'dustpan': 1, 'indoors': 1, 'disposable': 1, 'becomes': 1, 'uninteresting': 2, 'forgettable': 1, 'bt250v': 1, 'rolled': 1, 'clipping': 1, 'deffinitely': 1, 'cent': 1, 'upandcoming': 1, '18': 1, 'verizons': 1, 'attempted': 1, 'truth': 1, 'reconciliation': 1, '1986': 1, 'version': 2, 'watchable': 1, 'strives': 1, 'greatness': 1, 'muddled': 1, 'disparate': 1, 'accurately': 1, 'defined': 1, 'ethic': 1, 'intended': 1, 'yellow': 1, 'saffron': 1, 'seasoning': 1, '400': 1, 'lassie': 1, 'sleep': 1, 'marble': 1, 'comparablypriced': 1, 'offering': 1, 'rubbish': 1, 'nonresearched': 1, 'located': 1, 'crystal': 1, 'shopping': 1, 'aria': 1, 'shakespear': 2, 'amp': 1, 'ians': 1, 'tasting': 1, 'jeff': 1, 'rendering': 1, 'imperial': 1, 'speaking': 1, 'unbearably': 1, 'kitchy': 1, 'capacity': 1, 'confortable': 1, 'onion': 1, 'tick': 1, 'shakespears': 1, 'lyric': 1, 'vegasthere': 1, 'bulky': 1, 'carlys': 1, 'based': 1, 'gratitude': 1, 'offered': 1, 'jennifer': 1, 'rubin': 1, 'harris': 1, 'nervous': 1, 'starlet': 1, 'generates': 1, 'austere': 1, 'backdrop': 1, 'subway': 4, 'meet': 1, 'proven': 1, 'accept': 2, 'cbr': 1, 'mp3s': 1, 'preferably': 1, 'modest': 1, 'cellular': 1, 'delete': 1, 'peter': 1, 'accessible': 1, 'foodand': 1, 'recognizes': 1, 'require': 1, 'puzzlesolving': 1, 'create': 1, 'dialing': 2, 'bank': 1, 'holiday': 1, 'rick': 1, 'earset': 1, 'outgoing': 1, 'general': 1, 'loewenhielms': 1, 'partaking': 1, 'cailles': 1, 'en': 1, 'sarcophage': 1, 'savor': 1, 'adhesive': 1, '680': 1, 'musicincluding': 1, 'shirley': 1, 'jones': 1, 'rendition': 1, 'greasy': 1, 'unhealthy': 1, 'hang': 1, 'understood': 1, 'themselves': 1, 'identified': 1, 'dustin': 1, 'hoffman': 1, 'mentioned': 1, 'indescribably': 1, 'idiotic': 1, 'irritating': 1, 'auto': 1, 'reverse': 1, 'tape': 1, 'encourage': 1, 'employee': 3, 'ringer': 1, 'perabo': 1, 'shallow': 1, 'insincere': 1, 'kieslowski': 1, 'cease': 1, 'amaze': 1, 'officially': 1, 'phonesmp3': 1, 'additional': 2, 'schr450': 1, 'slider': 1, 'premium': 1, 'president': 1, 'dealing': 3, 'worstannoying': 1, 'drunk': 1, 'download': 2, 'address': 1, 'rebootsoverall': 1, 'faultless': 1, 'underappreciated': 1, 'keith': 1, 'bully': 1, 'teddy': 1, 'vivid': 1, 'bloddy': 1, 'fond': 1, 'magnetic': 1, 'strap': 1, 'exceeding': 1, 'dreamed': 1, 'blist': 1, 'horrorsuspense': 1, 'badwellits': 1, 'constantine': 1, 'intensity': 1, 'motivation': 1, 'thorn': 1, 'abhor': 1, 'youll': 1, 'ignored': 1, 'hostess': 1, 'detachable': 1, 'hawaiian': 1, 'breeze': 1, 'mango': 1, 'magic': 1, 'pineapple': 1, 'smoothy': 1, 'artless': 1, 'endlessly': 1, 'ugliest': 1, 'definitly': 1, 'pretext': 1, 'excruciatingly': 1, 'qualified': 1, 'veteran': 1, 'nostalgia': 1, 'oldfashioned': 1, 'tuneful': 1, 'sent': 1, 'strike': 1, 'rushed': 1, 'do': 1, 'gringo': 1, 'sharing': 1, 'phrase': 1, 'owed': 1, 'few': 1}\n"
     ]
    }
   ],
   "source": [
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow_dict = word_freq.copy()\n",
    "# for k, v in word_freq.items():\n",
    "#      if v < 3:\n",
    "#             del narrow_dict[k]\n",
    "# len(narrow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vector_func(sentence):\n",
    "    feature_vector = {x:0 for x in word_freq} # Put 0-s instead of counting every unique word\n",
    "    word_list = sentence.split()\n",
    "    for word in feature_vector:\n",
    "        if word in word_list:\n",
    "            feature_vector[word] = feature_vector[word] + 1\n",
    "        else:\n",
    "            feature_vector[word] = feature_vector[word]\n",
    "    return(feature_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the function to all rows in df_train to get all feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['feature_vector_dict'] = df_train['sentence'].apply(lambda x: feature_vector_func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>feature_vector_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not mention combination pear almond bacon big ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not': 1, 'mention': 1, 'combination': 1, 'pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patio seating comfortable</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friend pasta also bad barely touched it</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>say food amazing</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food arrives meh</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  \\\n",
       "0  not mention combination pear almond bacon big ...      1   \n",
       "1                          patio seating comfortable      1   \n",
       "2            friend pasta also bad barely touched it      0   \n",
       "3                                   say food amazing      1   \n",
       "4                                   food arrives meh      0   \n",
       "\n",
       "                                 feature_vector_dict  \n",
       "0  {'not': 1, 'mention': 1, 'combination': 1, 'pe...  \n",
       "1  {'not': 0, 'mention': 0, 'combination': 0, 'pe...  \n",
       "2  {'not': 0, 'mention': 0, 'combination': 0, 'pe...  \n",
       "3  {'not': 0, 'mention': 0, 'combination': 0, 'pe...  \n",
       "4  {'not': 0, 'mention': 0, 'combination': 0, 'pe...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['feature_vector_dict'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the function to all rows in the same manner for df_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['feature_vector_dict'] = df_test['sentence'].apply(lambda x: feature_vector_func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>feature_vector_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>place nice surprise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>really impressive place closed down</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great food awesome service</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said abovepretty useless</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good case</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sentence  label  \\\n",
       "0                  place nice surprise      1   \n",
       "1  really impressive place closed down      0   \n",
       "2           great food awesome service      1   \n",
       "3             said abovepretty useless      0   \n",
       "4                            good case      1   \n",
       "\n",
       "                                 feature_vector_dict  \n",
       "0  {'not': 0, 'mention': 0, 'combination': 0, 'pe...  \n",
       "1  {'not': 0, 'mention': 0, 'combination': 0, 'pe...  \n",
       "2  {'not': 0, 'mention': 0, 'combination': 0, 'pe...  \n",
       "3  {'not': 0, 'mention': 0, 'combination': 0, 'pe...  \n",
       "4  {'not': 0, 'mention': 0, 'combination': 0, 'pe...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['feature_vector_dict'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare any two feature vectors of any two reviews in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'not': 1, 'mention': 1, 'combination': 1, 'pe...\n",
       "1    {'not': 0, 'mention': 0, 'combination': 0, 'pe...\n",
       "Name: feature_vector_dict, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['feature_vector_dict'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2(e) - Pick your postprocessing strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We chose to use the 4th method - standardize the data by subtracting the mean and dividing by the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization, on the other hand, can be helpful in cases where the data follows a Gaussian distribution. \n",
    "\n",
    "However, this does not have to be necessarily true. Also, unlike normalization, standardization does not have a bounding range. \n",
    "\n",
    "So, even if you have outliers in your data, they will not be affected by standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that converts the dict \"feature_vector\" into an array:\n",
    "def dict_to_array(vector):\n",
    "    data = list(vector.values())\n",
    "    an_array = np.array(data)\n",
    "    return(an_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self check\n",
    "# data = list(df_train['feature_vector'][1].values())\n",
    "# an_array = np.array(data)\n",
    "# print(an_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['feature_vector_array'] = df_train['feature_vector_dict'].apply(lambda x: dict_to_array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['feature_vector_array'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that gets \"df_train['array_vector'][i]\", and returns the standardized array:\n",
    "\n",
    "import itertools\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def standard(row):\n",
    "    standardized_array = scaler.fit_transform(np.array(row).reshape(-1,1))\n",
    "    return(standardized_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['standard_array'] = df_train['feature_vector_array'].apply(lambda x: standard(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23.21098878],\n",
       "       [23.21098878],\n",
       "       [23.21098878],\n",
       "       ...,\n",
       "       [-0.04308304],\n",
       "       [-0.04308304],\n",
       "       [-0.04308304]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#self check \n",
    "df_train['standard_array'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>feature_vector_dict</th>\n",
       "      <th>feature_vector_array</th>\n",
       "      <th>standard_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not mention combination pear almond bacon big ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not': 1, 'mention': 1, 'combination': 1, 'pe...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[23.210988776870316], [23.210988776870316], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patio seating comfortable</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[-0.026367577267139772], [-0.0263675772671397...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friend pasta also bad barely touched it</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[[-0.040295820993189777], [-0.0402958209931897...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>say food amazing</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[-0.026367577267139772], [-0.0263675772671397...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food arrives meh</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not': 0, 'mention': 0, 'combination': 0, 'pe...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[-0.026367577267139772], [-0.0263675772671397...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  \\\n",
       "0  not mention combination pear almond bacon big ...      1   \n",
       "1                          patio seating comfortable      1   \n",
       "2            friend pasta also bad barely touched it      0   \n",
       "3                                   say food amazing      1   \n",
       "4                                   food arrives meh      0   \n",
       "\n",
       "                                 feature_vector_dict  \\\n",
       "0  {'not': 1, 'mention': 1, 'combination': 1, 'pe...   \n",
       "1  {'not': 0, 'mention': 0, 'combination': 0, 'pe...   \n",
       "2  {'not': 0, 'mention': 0, 'combination': 0, 'pe...   \n",
       "3  {'not': 0, 'mention': 0, 'combination': 0, 'pe...   \n",
       "4  {'not': 0, 'mention': 0, 'combination': 0, 'pe...   \n",
       "\n",
       "                                feature_vector_array  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      standard_array  \n",
       "0  [[23.210988776870316], [23.210988776870316], [...  \n",
       "1  [[-0.026367577267139772], [-0.0263675772671397...  \n",
       "2  [[-0.040295820993189777], [-0.0402958209931897...  \n",
       "3  [[-0.026367577267139772], [-0.0263675772671397...  \n",
       "4  [[-0.026367577267139772], [-0.0263675772671397...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['feature_vector_array'] = df_test['feature_vector_dict'].apply(lambda x: dict_to_array(x))\n",
    "df_test['standard_array'] = df_test['feature_vector_array'].apply(lambda x: standard(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2(f) - Sentiment Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a naive Bayes model on the training set and test on the testing set. \n",
    "\n",
    "Report the classification accuracy and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the data for the Naive Bayes prediction:\n",
    "def array_of_arrays(row):\n",
    "    list_standard = []\n",
    "    for i in range(0, len(row)):\n",
    "        list_standard.append((row[i][0]))\n",
    "    return (np.array(list_standard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['standard_array_clean'] = df_train['standard_array'].apply(lambda x: array_of_arrays(x))\n",
    "df_test['standard_array_clean'] = df_test['standard_array'].apply(lambda x: array_of_arrays(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = df_train[\"standard_array_clean\"]\n",
    "test_X = df_test[\"standard_array_clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.DataFrame(train_X.to_list()).to_numpy()\n",
    "test_X = pd.DataFrame(test_X.to_list()).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Check that there is no \"Nan\" values:\n",
    "\n",
    "for array in test_X:\n",
    "    array_sum = np.sum(array)\n",
    "    array_has_nan = np.isnan(array_sum)\n",
    "print(array_has_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = df_train['label']\n",
    "test_Y = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = train_X.shape[0] #number of rows\n",
    "d = train_X.shape[1] #number of unique words = features in feature vector\n",
    "K = 2 #number of classes - label 1 or label 0\n",
    "\n",
    "psis = np.zeros([K,d])\n",
    "phis = np.zeros([K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    X_k = train_X[train_Y == k]\n",
    "    phis[k] = X_k.shape[0] / float(n)\n",
    "    psis[k] = np.mean(X_k, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(psis.shape, phis.shape, train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement this in numpy\n",
    "def nb_predictions(x, psis, phis):\n",
    "    # adjust shapes\n",
    "    n , d = x.shape\n",
    "    x = np.reshape(x, (1,n,d))\n",
    "    psis = np.reshape(psis, (K, 1, d))\n",
    "    \n",
    "    psis = psis.clip(1e-14, 1-1e-14) \n",
    "    \n",
    "    # compute log-probabilities\n",
    "    logpy = np.log(phis).reshape(K,1)\n",
    "    logpxy = x * np.log(psis) + (1-x) * np.log(1-psis)\n",
    "    logpyx = logpxy.sum(axis=2) + logpy\n",
    "\n",
    "    return logpyx.argmax(axis=0).flatten(), logpyx.reshape([K,n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes on the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train, logpyx = nb_predictions(train_X, psis, phis)\n",
    "# len(predicted_train), len(logpyx), predicted_train.shape, logpyx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8779166666666667"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_train == train_Y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test, logpyx_test = nb_predictions(test_X, psis, phis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7533333333333333"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_test == test_Y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = test_Y\n",
    "predictions = predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2102d4d6dc0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get actual and create heatmap \n",
    "confusion_matrix = pd.crosstab(actual, predictions , rownames=['Actual'], colnames=['Predicted'], normalize=True)\n",
    "plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2(g): Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_list = list(word_freq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_feat_vect = pd.DataFrame(df_train['feature_vector_array'].to_list())\n",
    "train_X_feat_vect.columns = list(word_freq.keys())\n",
    "test_X_feat_vect = pd.DataFrame(df_test['feature_vector_array'].to_list())\n",
    "test_X_feat_vect.columns = list(word_freq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge = LogisticRegressionCV(cv=10, penalty='l2', solver='liblinear').fit(train_X_feat_vect, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ridge_test = model_ridge.predict(test_X_feat_vect)\n",
    "predicted_ridge_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ridge.score(test_X_feat_vect, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2111c99e520>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get actual and create heatmap \n",
    "actual = test_Y\n",
    "predictions_ridge = predicted_ridge_test\n",
    "confusion_matrix = pd.crosstab(actual, predictions_ridge , rownames=['Actual'], colnames=['Predicted'], normalize=True)\n",
    "plt.subplots(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most and least important words for the ridge resgression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge.coef_\n",
    "coeffs_ridge = list(np.argsort(model_ridge.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great\n",
      "love\n",
      "delicious\n",
      "excellent\n",
      "fantastic\n",
      "nice\n",
      "awesome\n",
      "loved\n",
      "happier\n",
      "liked\n"
     ]
    }
   ],
   "source": [
    "# most important words:\n",
    "most_important = coeffs_ridge[0][::-1]\n",
    "for i in range(0,10):\n",
    "    print(unique_words_list[most_important[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poor\n",
      "bad\n",
      "disappointment\n",
      "not\n",
      "worst\n",
      "average\n",
      "slow\n",
      "awful\n",
      "terrible\n",
      "disappointing\n"
     ]
    }
   ],
   "source": [
    "least_important = coeffs_ridge[0]\n",
    "for i in range(0,10):\n",
    "    print(unique_words_list[least_important[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ophir\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\ophir\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "model_lasso = LogisticRegressionCV(cv=10, penalty='l1', solver='liblinear').fit(train_X_feat_vect, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lasso = model_lasso.predict(test_X_feat_vect)\n",
    "predict_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lasso.score(test_X_feat_vect, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21119375160>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "actual = test_Y\n",
    "predictions_lasso = predict_lasso\n",
    "confusion_matrix = pd.crosstab(actual, predictions_lasso , rownames=['Actual'], colnames=['Predicted'], normalize=True)\n",
    "plt.subplots(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso.coef_\n",
    "coeffs_lasso = list(np.argsort(model_lasso.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "happier\n",
      "distracting\n",
      "recommendation\n",
      "played\n",
      "great\n",
      "child\n",
      "delicious\n",
      "loved\n",
      "beautiful\n"
     ]
    }
   ],
   "source": [
    "# most important words:\n",
    "most_important = coeffs_lasso[0][::-1]\n",
    "for i in range(0,10):\n",
    "    print(unique_words_list[most_important[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flavorless\n",
      "rude\n",
      "methe\n",
      "break\n",
      "poor\n",
      "failed\n",
      "disappointment\n",
      "waited\n",
      "unfortunately\n",
      "slow\n"
     ]
    }
   ],
   "source": [
    "least_important = coeffs_lasso[0]\n",
    "for i in range(0,10):\n",
    "    print(unique_words_list[least_important[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a dictionary of n-gram (n=2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>place nice surprise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>really impressive place closed down</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great food awesome service</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said abovepretty useless</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good case</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>seriously killer hot chai latte</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>service thought good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>not answer call unit never worked once</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>rave review wait eat herewhat disappointment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>saggy floppy piece junk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sentence  label\n",
       "0                             place nice surprise      1\n",
       "1             really impressive place closed down      0\n",
       "2                      great food awesome service      1\n",
       "3                        said abovepretty useless      0\n",
       "4                                       good case      1\n",
       "..                                            ...    ...\n",
       "595               seriously killer hot chai latte      1\n",
       "596                          service thought good      1\n",
       "597        not answer call unit never worked once      0\n",
       "598  rave review wait eat herewhat disappointment      0\n",
       "599                       saggy floppy piece junk      0\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all two consecutive words in all rows in the dataframe: \n",
    "list_consecutive = []\n",
    "for row in range(0, len(df_train['sentence'])):\n",
    "    sentence = df_train['sentence'][row]\n",
    "    word_list = df_train['sentence'][row].split()\n",
    "    i=0\n",
    "    while i < len(word_list)-1:\n",
    "        if (word_list[i] + ' ' + word_list[i+1]) not in list_consecutive:\n",
    "            list_consecutive.append(word_list[i]+ ' ' + word_list[i+1])\n",
    "            i+=1\n",
    "        else:\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list_consecutive) #self-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list of consecutive into a dictionary\n",
    "ngram_dict = dict.fromkeys(list_consecutive, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat 2(d):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that return the two consecutive for every row in the dataframe:\n",
    "def consecutive(sentence):\n",
    "    list_cons_per_row = []\n",
    "    word_list = sentence.split()\n",
    "    i=0\n",
    "    while i < len(word_list)-1:\n",
    "        if (word_list[i] + ' ' + word_list[i+1]) not in list_cons_per_row:\n",
    "            list_cons_per_row.append(word_list[i]+ ' ' + word_list[i+1])\n",
    "            i+=1\n",
    "        else:\n",
    "            i+=1\n",
    "    return(list_cons_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_list_3 = consecutive(df_train['sentence'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word in word_list_3:\n",
    "#     print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram_dict['punishment park']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ngram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4318"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11751"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ngram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vector_func_ngram(sentence):\n",
    "    feature_vector_row = dict.fromkeys(ngram_dict, 0)\n",
    "    word_list = consecutive(sentence)\n",
    "    for word in word_list:\n",
    "        if word in ngram_dict:\n",
    "            feature_vector_row[word] = feature_vector_row[word] + 1\n",
    "        else:\n",
    "            pass\n",
    "    return(feature_vector_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ngram['feature_vector_dict_ngram'] = df_train_ngram['sentence'].apply(lambda x: feature_vector_func_ngram(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>feature_vector_dict_ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not mention combination pear almond bacon big ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not mention': 1, 'mention combination': 1, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patio seating comfortable</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friend pasta also bad barely touched it</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>say food amazing</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food arrives meh</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  \\\n",
       "0  not mention combination pear almond bacon big ...      1   \n",
       "1                          patio seating comfortable      1   \n",
       "2            friend pasta also bad barely touched it      0   \n",
       "3                                   say food amazing      1   \n",
       "4                                   food arrives meh      0   \n",
       "\n",
       "                           feature_vector_dict_ngram  \n",
       "0  {'not mention': 1, 'mention combination': 1, '...  \n",
       "1  {'not mention': 0, 'mention combination': 0, '...  \n",
       "2  {'not mention': 0, 'mention combination': 0, '...  \n",
       "3  {'not mention': 0, 'mention combination': 0, '...  \n",
       "4  {'not mention': 0, 'mention combination': 0, '...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ngram.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the function to all rows in the same manner for df_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ngram['feature_vector_dict_ngram'] = df_test_ngram['sentence'].apply(lambda x: feature_vector_func_ngram(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>feature_vector_dict_ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>place nice surprise</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>really impressive place closed down</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great food awesome service</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said abovepretty useless</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good case</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sentence  label  \\\n",
       "0                  place nice surprise      1   \n",
       "1  really impressive place closed down      0   \n",
       "2           great food awesome service      1   \n",
       "3             said abovepretty useless      0   \n",
       "4                            good case      1   \n",
       "\n",
       "                           feature_vector_dict_ngram  \n",
       "0  {'not mention': 0, 'mention combination': 0, '...  \n",
       "1  {'not mention': 0, 'mention combination': 0, '...  \n",
       "2  {'not mention': 0, 'mention combination': 0, '...  \n",
       "3  {'not mention': 0, 'mention combination': 0, '...  \n",
       "4  {'not mention': 0, 'mention combination': 0, '...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_ngram.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare any two feature vectors of any two reviews in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'not mention': 1, 'mention combination': 1, '...\n",
       "1    {'not mention': 0, 'mention combination': 0, '...\n",
       "Name: feature_vector_dict_ngram, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ngram['feature_vector_dict_ngram'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat 2(e) - Postprocessing Strategy with ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ngram['feature_vector_array_ngram'] = df_train_ngram['feature_vector_dict_ngram'].apply(lambda x: dict_to_array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>feature_vector_dict_ngram</th>\n",
       "      <th>feature_vector_array_ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not mention combination pear almond bacon big ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not mention': 1, 'mention combination': 1, '...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patio seating comfortable</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friend pasta also bad barely touched it</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>say food amazing</td>\n",
       "      <td>1</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food arrives meh</td>\n",
       "      <td>0</td>\n",
       "      <td>{'not mention': 0, 'mention combination': 0, '...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  \\\n",
       "0  not mention combination pear almond bacon big ...      1   \n",
       "1                          patio seating comfortable      1   \n",
       "2            friend pasta also bad barely touched it      0   \n",
       "3                                   say food amazing      1   \n",
       "4                                   food arrives meh      0   \n",
       "\n",
       "                           feature_vector_dict_ngram  \\\n",
       "0  {'not mention': 1, 'mention combination': 1, '...   \n",
       "1  {'not mention': 0, 'mention combination': 0, '...   \n",
       "2  {'not mention': 0, 'mention combination': 0, '...   \n",
       "3  {'not mention': 0, 'mention combination': 0, '...   \n",
       "4  {'not mention': 0, 'mention combination': 0, '...   \n",
       "\n",
       "                          feature_vector_array_ngram  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ngram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ngram['standard_array_ngram'] = df_train_ngram['feature_vector_array_ngram'].apply(lambda x: standard(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ngram['feature_vector_array_ngram'] = df_test_ngram['feature_vector_dict_ngram'].apply(lambda x: dict_to_array(x))\n",
    "df_test_ngram['standard_array_ngram'] = df_test_ngram['feature_vector_array_ngram'].apply(lambda x: standard(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11751"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_ngram['standard_array_ngram'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reapeat 2(f) - Sentiment Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a naive Bayes model on the training set and test on the testing set. \n",
    "\n",
    "Report the classification accuracy and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ngram['standard_array_clean_ngram'] = df_train_ngram['standard_array_ngram'].apply(lambda x: array_of_arrays(x))\n",
    "df_test_ngram['standard_array_clean_ngram'] = df_test_ngram['standard_array_ngram'].apply(lambda x: array_of_arrays(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11751"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_ngram['standard_array_clean_ngram'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_ngram = df_train_ngram[\"standard_array_clean_ngram\"]\n",
    "test_X_ngram = df_test_ngram[\"standard_array_clean_ngram\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Check that there is no \"Nan\" values:\n",
    "for array in test_X_ngram:\n",
    "    array_sum = np.sum(array)\n",
    "    array_has_nan = np.isnan(array_sum)\n",
    "print(array_has_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False = no \"Nan\" values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_ngram = pd.DataFrame(train_X_ngram.to_list())\n",
    "# train_X_ngram = train_X_ngram.loc[:, :3753]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Check again - no \"Nan\" values\n",
    "for array in test_X_ngram:\n",
    "    array_sum = np.sum(array)\n",
    "    array_has_nan = np.isnan(array_sum)\n",
    "print(array_has_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_ngram = train_X_ngram.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11751"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_ngram.shape[1] #works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11741</th>\n",
       "      <th>11742</th>\n",
       "      <th>11743</th>\n",
       "      <th>11744</th>\n",
       "      <th>11745</th>\n",
       "      <th>11746</th>\n",
       "      <th>11747</th>\n",
       "      <th>11748</th>\n",
       "      <th>11749</th>\n",
       "      <th>11750</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 11751 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6      \\\n",
       "0    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   -0.013047 -0.013047 -0.013047 -0.013047 -0.013047 -0.013047 -0.013047   \n",
       "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "595  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "596 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225   \n",
       "597 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225   \n",
       "598  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "599 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225   \n",
       "\n",
       "        7         8         9      ...     11741     11742     11743  \\\n",
       "0    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2   -0.013047 -0.013047 -0.013047  ... -0.013047 -0.013047 -0.013047   \n",
       "3    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4   -0.009225 -0.009225 -0.009225  ... -0.009225 -0.009225 -0.009225   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "595  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "596 -0.009225 -0.009225 -0.009225  ... -0.009225 -0.009225 -0.009225   \n",
       "597 -0.009225 -0.009225 -0.009225  ... -0.009225 -0.009225 -0.009225   \n",
       "598  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "599 -0.009225 -0.009225 -0.009225  ... -0.009225 -0.009225 -0.009225   \n",
       "\n",
       "        11744     11745     11746     11747     11748     11749     11750  \n",
       "0    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2   -0.013047 -0.013047 -0.013047 -0.013047 -0.013047 -0.013047 -0.013047  \n",
       "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4   -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "595  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "596 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225  \n",
       "597 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225  \n",
       "598  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "599 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225  \n",
       "\n",
       "[600 rows x 11751 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_ngram = pd.DataFrame(test_X_ngram.to_list())\n",
    "test_X_ngram #I see there is redundant data - drop all columns after 3756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11741</th>\n",
       "      <th>11742</th>\n",
       "      <th>11743</th>\n",
       "      <th>11744</th>\n",
       "      <th>11745</th>\n",
       "      <th>11746</th>\n",
       "      <th>11747</th>\n",
       "      <th>11748</th>\n",
       "      <th>11749</th>\n",
       "      <th>11750</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "      <td>-0.013047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "      <td>-0.009225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 11751 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6      \\\n",
       "0    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   -0.013047 -0.013047 -0.013047 -0.013047 -0.013047 -0.013047 -0.013047   \n",
       "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "595  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "596 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225   \n",
       "597 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225   \n",
       "598  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "599 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225   \n",
       "\n",
       "        7         8         9      ...     11741     11742     11743  \\\n",
       "0    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2   -0.013047 -0.013047 -0.013047  ... -0.013047 -0.013047 -0.013047   \n",
       "3    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4   -0.009225 -0.009225 -0.009225  ... -0.009225 -0.009225 -0.009225   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "595  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "596 -0.009225 -0.009225 -0.009225  ... -0.009225 -0.009225 -0.009225   \n",
       "597 -0.009225 -0.009225 -0.009225  ... -0.009225 -0.009225 -0.009225   \n",
       "598  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "599 -0.009225 -0.009225 -0.009225  ... -0.009225 -0.009225 -0.009225   \n",
       "\n",
       "        11744     11745     11746     11747     11748     11749     11750  \n",
       "0    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2   -0.013047 -0.013047 -0.013047 -0.013047 -0.013047 -0.013047 -0.013047  \n",
       "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4   -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "595  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "596 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225  \n",
       "597 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225  \n",
       "598  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "599 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225 -0.009225  \n",
       "\n",
       "[600 rows x 11751 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping redundant columns\n",
    "test_X_ngram   #= test_X_ngram.loc[:, :3755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#check there is no \"Nan\" values\n",
    "for array in test_X_ngram:\n",
    "    array_sum = np.sum(array)\n",
    "    array_has_nan = np.isnan(array_sum)\n",
    "print(array_has_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False - we can continue:\n",
    "test_X_ngram = test_X_ngram.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 11751)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_ngram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_ngram = df_train['label']\n",
    "test_Y_ngram = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = train_X_ngram.shape[0] #number of rows\n",
    "d = train_X_ngram.shape[1] #number of unique words = features in feature vector\n",
    "K = 2 #number of classes - label 1 or label 0\n",
    "\n",
    "psis = np.zeros([K,d])\n",
    "phis = np.zeros([K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    X_k_ngram = train_X_ngram[train_Y_ngram == k]\n",
    "    phis[k] = X_k_ngram.shape[0] / float(n)\n",
    "    psis[k] = np.mean(X_k_ngram, axis=0) #build a function with the mean for label 0 and mean for label 0 as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 11751) (2,) (2400, 11751)\n"
     ]
    }
   ],
   "source": [
    "print(psis.shape, phis.shape, train_X_ngram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement this in numpy\n",
    "def nb_predictions(x, psis, phis):\n",
    "    \"\"\"This returns class assignments and scores under the NB model.\n",
    "    \n",
    "    We compute \\arg\\max_y p(y|x) as \\arg\\max_y p(x|y)p(y)\n",
    "    \"\"\"\n",
    "    # adjust shapes\n",
    "    n , d = x.shape\n",
    "    x = np.reshape(x, (1,n,d))\n",
    "    psis = np.reshape(psis, (K, 1, d))\n",
    "    \n",
    "    # clip probabilities to avoid log(0)\n",
    "    psis = psis.clip(1e-14, 1-1e-14) #understand\n",
    "    \n",
    "    # compute log-probabilities\n",
    "    logpy = np.log(phis).reshape(K,1)\n",
    "    logpxy = x * np.log(psis) + (1-x) * np.log(1-psis)\n",
    "    logpyx = logpxy.sum(axis=2) + logpy\n",
    "\n",
    "    return logpyx.argmax(axis=0).flatten(), logpyx.reshape([K,n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes on the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train_ngram, logpyx_ngram = nb_predictions(train_X_ngram, psis, phis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in predicted_train_ngram:\n",
    "#     if i != 0:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9883333333333333"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_train_ngram == train_Y_ngram).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_ngram, logpyx_test = nb_predictions(test_X_ngram, psis, phis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6633333333333333"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted_test_ngram == test_Y_ngram).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ngram = test_Y_ngram\n",
    "predictions_ngram = predicted_test_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_ngram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_ngram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2101389da00>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get actual and create heatmap \n",
    "confusion_matrix_ngram = pd.crosstab(actual_ngram, predictions_ngram , rownames=['Actual'], colnames=['Predicted'], normalize=True)\n",
    "plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_ngram, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat 2(g): Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_feat_vect_ngram = pd.DataFrame(df_train_ngram['feature_vector_array_ngram'].to_list())\n",
    "train_X_feat_vect_ngram.columns = list(ngram_dict.keys())\n",
    "test_X_feat_vect_ngram = pd.DataFrame(df_test_ngram['feature_vector_array_ngram'].to_list())\n",
    "# test_X_feat_vect_ngram = test_X_feat_vect_ngram.loc[:, :3755]\n",
    "test_X_feat_vect_ngram.columns = list(ngram_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge_ngram = LogisticRegressionCV(cv=10, penalty='l2', solver='liblinear').fit(train_X_feat_vect_ngram, train_Y_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test_ridge = model_ridge_ngram.predict(test_X_feat_vect_ngram)\n",
    "predicted_test_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6516666666666666"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ridge_ngram.score(test_X_feat_vect_ngram, test_Y_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2102c497c70>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get actual and create heatmap \n",
    "actual_ngram = test_Y_ngram\n",
    "predictions_ridge_ngram = predicted_test_ridge\n",
    "confusion_matrix_ngram = pd.crosstab(actual_ngram, predictions_ridge_ngram, rownames=['Actual'], colnames=['Predicted'], normalize=True)\n",
    "plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_ngram, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most and least important words for the ridge resgression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge_ngram.coef_\n",
    "coeffs_ridge_ngram = list(np.argsort(model_ridge_ngram.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ngram = list(ngram_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joke told\n",
      "website followed\n",
      "pretty tasteless\n",
      "sound like\n",
      "quite honestly\n",
      "nun church\n",
      "conclusion not\n",
      "return unit\n",
      "self proclaimed\n",
      "oyster were\n"
     ]
    }
   ],
   "source": [
    "# most important words:\n",
    "most_important_ngram = coeffs_ridge_ngram[0][::-1]\n",
    "for i in range(0,10):\n",
    "    print(list_ngram[most_important[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home time\n",
      "wait it\n",
      "woman there\n",
      "sturdy nokia\n",
      "effect phone\n",
      "avoid place\n",
      "took 40\n",
      "female character\n",
      "hate earbugs\n",
      "dialogue hopeless\n"
     ]
    }
   ],
   "source": [
    "least_important_ngram = coeffs_ridge_ngram[0]\n",
    "for i in range(0,10):\n",
    "    print(list_ngram[least_important[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso_ngram = LogisticRegressionCV(cv=10, penalty='l1', solver='liblinear').fit(train_X_feat_vect_ngram, train_Y_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test_lasso = model_lasso_ngram.predict(test_X_feat_vect_ngram)\n",
    "predicted_test_lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6433333333333333"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lasso_ngram.score(test_X_feat_vect_ngram, test_Y_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x210131bfca0>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get actual and create heatmap \n",
    "actual_ngram = test_Y_ngram\n",
    "predictions_lasso_ngram = predicted_test_lasso\n",
    "confusion_matrix_ngram_lasso = pd.crosstab(actual_ngram, predictions_lasso_ngram, rownames=['Actual'], colnames=['Predicted'], normalize=True)\n",
    "plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_ngram_lasso, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Comparison and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above results, compare the performances of naive Bayes, logistic regression, naive Bayes with 2-grams, and logistic regression\n",
    "with 2-grams. Which method performs best in the prediction task and why? What do you\n",
    "learn about the language that people use in online reviews (e.g., expressions that will make\n",
    "the posts positive/negative)? Hint: Inspect the weights learned from logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general - part (1) is better than part (2).\n",
    "\n",
    "In n-gram model:\n",
    "    lasso accuracy < ridge accuracy because Lasso penalizes for many features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
